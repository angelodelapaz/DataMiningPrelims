{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Import & Exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the large dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "fies_df = pd.read_csv('../datasets/fies_2023_volume1_494887610821.csv')\n",
    "fies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Identifying Data and Attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List all column types and data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_and_datatypes = pd.DataFrame({\n",
    "    'Data Type': fies_df.dtypes\n",
    "}, index=fies_df.columns)\n",
    "# Display all rows of the DataFrame\n",
    "for index, row in columns_and_datatypes.iterrows():\n",
    "    print(f\"{index}: {row['Data Type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All columns seem to be either an integer or a float value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to remove \"\" from column names\n",
    "fies_df.columns = fies_df.columns.str.strip('\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Determining the Type of Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if columns are numerical, categorical, or mixed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_check = pd.DataFrame({\n",
    "    'Column Type': None\n",
    "}, index=fies_df.columns)\n",
    "\n",
    "for column in fies_df.columns:\n",
    "    column_check['Column Type'] = pd.api.types.infer_dtype(fies_df[column])\n",
    "\n",
    "for index, row in column_check.iterrows():\n",
    "    print(f\"{index}: {row['Column Type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the columns seem to be numerical. However, an excel file that contains all metadata on what certain numbers in certain columns mean is provided by the PSA, (ex. Region Number Equivalents).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Data Dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fies_column_descriptions = {\n",
    "    'RDMD_ID': 'Unique identifier for the record',\n",
    "    'Region': 'Region code',\n",
    "    'Province': 'Province code',\n",
    "    'Household ID': 'Unique household identifier',\n",
    "    'RECODED PROVINCE': 'Recoded province information',\n",
    "    'Family Size': 'Number of people in the household',\n",
    "    'Salaries/Wages from Regular Employment': 'Income from regular employment',\n",
    "    'Salaries/Wages from Seasonal Employment': 'Income from seasonal employment',\n",
    "    'Income from Salaries and Wages': 'Total income from salaries and wages',\n",
    "    'Net Share of Crops, Fruits, etc. (Tot. Net Value of Share)': 'Net value from crop and fruit share',\n",
    "    'Cash Receipts, Support, etc. from Abroad': 'Cash support received from abroad',\n",
    "    'Cash Receipts, Support, etc. from Domestic Source': 'Cash support received domestically',\n",
    "    'Rentals Received from Non-Agri Lands, etc.': 'Income from land rentals (non-agricultural)',\n",
    "    'Unnamed: 13': 'Unknown or unnamed column',\n",
    "    'Pension and Retirement Benefits': 'Income from pensions and retirement',\n",
    "    'Dividends from Investment': 'Income from dividends',\n",
    "    'Other Sources of Income NEC': 'Other sources of income not elsewhere classified',\n",
    "    'Family Sustenance Activities': 'Income from family sustenance activities',\n",
    "    'Total Received as Gifts': 'Total gifts received by the household',\n",
    "    'Crop Farming and Gardening': 'Income from crop farming and gardening',\n",
    "    'Livestock and Poultry Raising': 'Income from livestock and poultry raising',\n",
    "    'Fishing': 'Income from fishing activities',\n",
    "    'Forestry and Hunting': 'Income from forestry and hunting',\n",
    "    'Wholesale and Retail': 'Income from wholesale and retail business',\n",
    "    'Manufacturing': 'Income from manufacturing activities',\n",
    "    'Transportation, Storage Services': 'Income from transportation and storage services',\n",
    "    'Entrep. Activities NEC': 'Income from entrepreneurial activities (not elsewhere classified)',\n",
    "    'Entrep. Activities NEC.1': 'Income from entrepreneurial activities (additional category 1)',\n",
    "    'Entrep. Activities NEC.2': 'Income from entrepreneurial activities (additional category 2)',\n",
    "    'Hhld, Income from Entrepreneurial Activities, Total': 'Total household income from entrepreneurial activities',\n",
    "    'Losses from EA': 'Losses from entrepreneurial activities',\n",
    "    'Cereal and Cereal Preparations (Total)': 'Expenditure on cereals and cereal preparations',\n",
    "    'Meat and Meat Preparations': 'Expenditure on meat and meat preparations',\n",
    "    'Fish and Marine Products (Total)': 'Expenditure on fish and marine products',\n",
    "    'Dairy Products and Eggs (Total)': 'Expenditure on dairy products and eggs',\n",
    "    'Oils and Fats (Total)': 'Expenditure on oils and fats',\n",
    "    'Fruits and Vegetables': 'Expenditure on fruits and vegetables',\n",
    "    'Vegetables (Total)': 'Expenditure on vegetables',\n",
    "    'Sugar, Jam and Honey (Total)': 'Expenditure on sugar, jam, and honey',\n",
    "    'Food Not Elsewhere Classified (Total)': 'Expenditure on other food items',\n",
    "    'Fruit and vegetable juices': 'Expenditure on fruit and vegetable juices',\n",
    "    'Coffee, Cocoa and Tea (Total)': 'Expenditure on coffee, cocoa, and tea',\n",
    "    'Tea (total)  expenditure': 'Expenditure on tea',\n",
    "    'Cocoa (total)  expenditure': 'Expenditure on cocoa',\n",
    "    'Main Source of Water Supply (2nd visit only)': 'Main source of water supply (second visit)',\n",
    "    'Softdrinks': 'Expenditure on soft drinks',\n",
    "    'Other Non Alcoholic Beverages': 'Expenditure on other non-alcoholic beverages',\n",
    "    'Alcoholic Beverages (Total)': 'Expenditure on alcoholic beverages',\n",
    "    'Tobacco (Total)': 'Expenditure on tobacco products',\n",
    "    'Other Vegetables (Total)': 'Expenditure on other types of vegetables',\n",
    "    'Services_Primary_Goods': 'Expenditure on services and primary goods',\n",
    "    'Alcohol Procduction Services': 'Expenditure on alcohol production services',\n",
    "    'Total Food Consumed at Home (Total)': 'Total food consumed at home',\n",
    "    'Food Regularly Consumed Outside The Home (Total)': 'Food consumed outside the home',\n",
    "    'Hhld, Food': 'Household expenditure on food',\n",
    "    'Clothing, Footwear and Other Wear': 'Expenditure on clothing, footwear, and other wear',\n",
    "    'Housing and water (Total)': 'Expenditure on housing and water',\n",
    "    'Actual House Rent': 'Expenditure on actual house rent',\n",
    "    'Imputed House Rental Value': 'Imputed value of house rental',\n",
    "    'Imputed Housing Benefit Rental Value': 'Imputed value of housing benefit rental',\n",
    "    'House Rent/Rental Value': 'Expenditure on house rent/rental value',\n",
    "    'Furnishings, Household Equipment & Routine Household Mainte': 'Expenditure on furnishings and household equipment',\n",
    "    'Health (Total)': 'Expenditure on health services and products',\n",
    "    'Transportation (Total)': 'Expenditure on transportation',\n",
    "    'Communication (Total)': 'Expenditure on communication services',\n",
    "    'Recreation and Culture (Total)': 'Expenditure on recreation and culture',\n",
    "    'Education (Total)': 'Expenditure on education',\n",
    "    'Insurance': 'Expenditure on insurance',\n",
    "    'Miscellaneous Goods and Services (Total)': 'Expenditure on miscellaneous goods and services',\n",
    "    'Durable Furniture': 'Expenditure on durable furniture',\n",
    "    'Special Family Occasion': 'Expenditure on special family occasions',\n",
    "    'Other Expenditure (inc. Value Consumed, Losses)': 'Other expenditures including losses',\n",
    "    'Other Disbursements': 'Other household disbursements',\n",
    "    'Accomodation Services': 'Expenditure on accommodation services',\n",
    "    'Total Non-Food Expenditure': 'Total non-food expenditure',\n",
    "    'Hhld, Income, Total': 'Total household income',\n",
    "    'Hhld, Expenditures, Total': 'Total household expenditures',\n",
    "    'Total Household Disbursements': 'Total household disbursements',\n",
    "    'Other Receipts': 'Other household receipts',\n",
    "    'Total Receipts': 'Total receipts',\n",
    "    'Psu (Recode)': 'Primary Sampling Unit (recoded)',\n",
    "    'Raising Factor': 'Raising factor for survey results',\n",
    "    'Final Population Weights': 'Final weights for population data',\n",
    "    'Urban / Rural': 'Urban or rural classification',\n",
    "    'Per Capita Income': 'Household per capita income',\n",
    "    'NPCINC': 'National per capita income',\n",
    "    'RPCINC': 'Regional per capita income',\n",
    "    'Per Capita Income Decile (Province)': 'Per capita income decile in the province',\n",
    "    'pPCINC': 'Provincial per capita income decile',\n",
    "    'Per Capita Income Decile (Region with Negros Island Region (NIR))': 'Per capita income decile (region with NIR)',\n",
    "    'Region (with NIR)': 'Region code including NIR'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fies_derivations = {\n",
    "    'Total Receipts': 'Total Household Income + Other Receipts',\n",
    "    'Hhld, Income, Total': 'Net Share of Crops, Fruits, etc. + Cash Receipts, Support, etc. from Abroad + Cash Receipts, Support, etc. from Domestic Source + Unnamed + Pension and Retirement Benefits + Dividends from Investment + Other Sources of Income NEC + Family Sustenance Activities + Total Received as Gifts + Household, Income from Entrep Activities, Total + Imputed House Rental Value',\n",
    "    'Hhld, Income from Entrepreneurial Activities, Total': 'Crop Farming and Gardening + Livestock and Poultry Raising + Fishing + Forestry and Hunting + Wholesale and Retail + Manufacturing + Transportation, Storage Services + Entrep. Activities NEC + Entrep. Activities NEC 1 + Entrep. Activities NEC 2',\n",
    "    'Total Household Disbursements': 'Total Household Expenditure + Other Disbursements',\n",
    "    'Hhld, Expenditures, Total': 'Household Food + Total Non-Food Expenditure',\n",
    "    'Hhld, Food': 'Total Food Consumed at Home + Food Regularly Consumed Outside The Home',\n",
    "    'Total Food Consumed at Home (Total)': 'Cereal and Cereal Preparations + Meat and Meat Preparations + Fish and Marine Products + Dairy and Eggs + Oils and Fats + Fruits and Vegetables + Vegetables + Sugar, jam and Honey + Food Not Elsewhere Classified + Fruit and Vegetable Juices + Coffee, Cocoa and Tea + Tea + Cocoa + Main Source of Water Supply + Softdrinks + Other Non Alcoholic Beverages',\n",
    "    'Total Non-Food Expenditure': 'Alcoholic Beverages + Tobacco + Other Vegetables + Services_Primary_Goods + Alcoholic Production Services + Housing and water (Total) + Furnishings, Household Equipment & Routine Household Maintenance + Health + Transportation + Communication + Recreation and Culture + Education + Insurance + Miscellaneous Goods and Services + Durable Furniture + Special Family Occasion + Other Expenditure + Accommodation Services + Clothing, Footwear and Other Wear',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fies_volume1_data_dict = pd.DataFrame({\n",
    "    'Column Name': fies_df.columns,\n",
    "    'Data Type': fies_df.dtypes,\n",
    "    'Non-Null Count': fies_df.notnull().sum(),\n",
    "    'Unique Values': fies_df.nunique(),\n",
    "    'Description': [fies_column_descriptions.get(col, 'No desciption available') for col in fies_df.columns],\n",
    "    'Derivations from other columns': [fies_derivations.get(col, '') for col in fies_df.columns]\n",
    "})\n",
    "fies_volume1_data_dict.to_csv('../fies_volume1_data_dict.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Quality and Assessment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing values, duplicates, outliers, and wrong data.<b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_rows = fies_df.shape[0]\n",
    "\n",
    "print(f\"Number of rows: {number_of_rows}\")\n",
    "\n",
    "removed_duplicates = fies_df.copy()\n",
    "removed_duplicates.drop_duplicates(inplace=True)\n",
    "\n",
    "print(f\"Number of rows after dropping duplicates: {removed_duplicates.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicates are found.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data dictionary, the Total Household Disbursements column is the only one with an object datatype, suggesting mixed values of numbers, strings, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in removed_duplicates.columns:\n",
    "    if removed_duplicates[column].isnull().any():\n",
    "        print(f\"Column {column} has missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block above does not show any null values initially, therefore there is the possibility of data with only whitespace values. The code below will strip all whitespaces\n",
    "to know the true number of missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a value is whitespace or empty\n",
    "def has_whitespace(val):\n",
    "    return isinstance(val, str) and val.strip() == ''\n",
    "\n",
    "whitespace_rows = removed_duplicates.map(has_whitespace).any(axis=1)\n",
    "\n",
    "whitespace_count = whitespace_rows.sum()\n",
    "\n",
    "print(f\"Number of rows with whitespace: {whitespace_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are whitespaces. Whitespaces could mean that the value for that data is zero. Therefore, a check must be made to ensure that there are zeroes in the dataset as well to know that whitespaces and zeroes are equivalent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(removed_duplicates['Total Household Disbursements'].value_counts().where(removed_duplicates['Total Household Disbursements'] == 0, 1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we detect potential outliers using statistical methods.\n",
    "The main columns to look at are the Total Household Income and Total Household Expenditure columns..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_mean = removed_duplicates['Hhld, Income, Total'].mean()\n",
    "income_median = removed_duplicates['Hhld, Income, Total'].median()\n",
    "income_std = removed_duplicates['Hhld, Income, Total'].std()\n",
    "\n",
    "print(f\"Income Mean: {income_mean}\")\n",
    "print(f\"Income Median: {income_median}\")\n",
    "print(f\"Income Standard Deviation: {income_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditure_mean = removed_duplicates['Hhld, Expenditures, Total'].mean()\n",
    "expenditure_median = removed_duplicates['Hhld, Expenditures, Total'].median()\n",
    "expenditure_std = removed_duplicates['Hhld, Expenditures, Total'].std()\n",
    "\n",
    "print(f\"Expenditure Mean: {expenditure_mean}\")\n",
    "print(f\"Expenditure Median: {expenditure_median}\")\n",
    "print(f\"Expenditure Standard Deviation: {expenditure_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results, the mean for the income and expenditure columns are quite large. To see more, a boxplot can be used to visualize the distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.boxplot(removed_duplicates['Hhld, Income, Total'])\n",
    "plt.title('Boxplot of Income')\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(removed_duplicates['Hhld, Expenditures, Total'])\n",
    "plt.title('Boxplot of Expenditures')\n",
    "plt.xlabel('Expenditures')\n",
    "plt.ylabel('Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.scatter(removed_duplicates['Hhld, Income, Total'], removed_duplicates['Hhld, Expenditures, Total'])\n",
    "ax.set_xlabel('Income')\n",
    "ax.set_ylabel('Expenditure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the boxplots and scatter plots, there defenitely are high-value outliers for both Income and Expenditure, and from the column derivations, this also means that by addressing only these two columns, the rest of the outlier columns can be addressed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute, discretize and data wrangling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are zeroes present, the Total Household Disbursements column must be addressed. Upon inspection, Total Household Disbursements can be imputed from the sum of Hhld, Expenditures, Total and Other Disbursements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_null = removed_duplicates.copy()\n",
    "removed_null.loc[whitespace_rows, 'Total Household Disbursements'] = removed_null.loc[whitespace_rows, \n",
    "                                                                            'Hhld, Expenditures, Total'] + removed_null.loc[whitespace_rows, 'Other Disbursements']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-check for missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitespace_rows = removed_null.map(has_whitespace).any(axis=1)\n",
    "whitespace_count = whitespace_rows.sum()\n",
    "print(f\"Number of rows with whitespace: {whitespace_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now address the outliers using the IQR method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_Q1 = removed_null['Hhld, Income, Total'].quantile(0.25)\n",
    "income_Q3 = removed_null['Hhld, Income, Total'].quantile(0.75)\n",
    "income_IQR = income_Q3 - income_Q1\n",
    "print(f\"Income Q1: {income_Q1}\")\n",
    "print(f\"Income Q3: {income_Q3}\")\n",
    "print(f\"Income IQR: {income_IQR}\")\n",
    "\n",
    "expenditure_Q1 = removed_null['Hhld, Expenditures, Total'].quantile(0.25)\n",
    "expenditure_Q3 = removed_null['Hhld, Expenditures, Total'].quantile(0.75)\n",
    "expenditure_IQR = expenditure_Q3 - expenditure_Q1\n",
    "print(f\"Expenditure Q1: {expenditure_Q1}\")\n",
    "print(f\"Expenditure Q3: {expenditure_Q3}\")\n",
    "print(f\"Expenditure IQR: {expenditure_IQR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Income\n",
    "removed_outliers = removed_null.copy()\n",
    "print('Shape before removing outliers:', removed_outliers.shape)\n",
    "lower_bound_income = income_Q1 - 1.5 * income_IQR\n",
    "upper_bound_income = income_Q3 + 1.5 * income_IQR\n",
    "upper_income = np.where(removed_outliers['Hhld, Income, Total'] >= upper_bound_income)[0]\n",
    "lower_income = np.where(removed_outliers['Hhld, Income, Total'] <= lower_bound_income)[0]\n",
    "\n",
    "removed_outliers.drop(index=upper_income, inplace=True)\n",
    "removed_outliers.drop(index=lower_income, inplace=True)\n",
    "print('Shape after removing outliers for Income:', removed_outliers.shape)\n",
    "\n",
    "# Expenditure\n",
    "lower_bound_expenditure = expenditure_Q1 - 1.5 * expenditure_IQR\n",
    "upper_bound_expenditure = expenditure_Q3 + 1.5 * expenditure_IQR\n",
    "removed_outliers.reset_index(drop=True, inplace=True)\n",
    "upper_expenditure = np.where(removed_outliers['Hhld, Expenditures, Total'] >= upper_bound_expenditure)[0]\n",
    "lower_expenditure = np.where(removed_outliers['Hhld, Expenditures, Total'] <= lower_bound_expenditure)[0]\n",
    "\n",
    "removed_outliers.drop(index=upper_expenditure, inplace=True)\n",
    "removed_outliers.drop(index=lower_expenditure, inplace=True)\n",
    "print('Shape after removing outliers for Expenditure:', removed_outliers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to check using the same methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_mean = removed_outliers['Hhld, Income, Total'].mean()\n",
    "income_median = removed_outliers['Hhld, Income, Total'].median()\n",
    "income_std = removed_outliers['Hhld, Income, Total'].std()\n",
    "\n",
    "print(f\"Income Mean: {income_mean}\")\n",
    "print(f\"Income Median: {income_median}\")\n",
    "print(f\"Income Standard Deviation: {income_std}\")\n",
    "\n",
    "expenditure_mean = removed_outliers['Hhld, Expenditures, Total'].mean()\n",
    "expenditure_median = removed_outliers['Hhld, Expenditures, Total'].median()\n",
    "expenditure_std = removed_outliers['Hhld, Expenditures, Total'].std()\n",
    "\n",
    "print(f\"Expenditure Mean: {expenditure_mean}\")\n",
    "print(f\"Expenditure Median: {expenditure_median}\")\n",
    "print(f\"Expenditure Standard Deviation: {expenditure_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(removed_outliers['Hhld, Income, Total'])\n",
    "plt.title('Boxplot of Income')\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(removed_outliers['Hhld, Expenditures, Total'])\n",
    "plt.title('Boxplot of Expenditures')\n",
    "plt.xlabel('Expenditures')\n",
    "plt.ylabel('Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.scatter(removed_outliers['Hhld, Income, Total'], removed_outliers['Hhld, Expenditures, Total'])\n",
    "ax.set_xlabel('Income')\n",
    "ax.set_ylabel('Expenditure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outliers are now removed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a column named Unnamed_13 in the dataset. We opted to total the unnamed column and other sources of income NEC because the unnamed column contributes to the total income of the household as some of the total income were inaccurate if the unnamed column wans't included\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputted_column_13 = removed_outliers.copy()\n",
    "imputted_column_13['Other Sources of Income NEC'] = imputted_column_13['Other Sources of Income NEC'] + imputted_column_13['Unnamed: 13']\n",
    "print(\"Number of columns before dropping:\", imputted_column_13.shape[1])\n",
    "imputted_column_13.drop(columns=['Unnamed: 13'], inplace=True)\n",
    "print(\"Number of columns after dropping:\", imputted_column_13.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Quantitative Statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate statistics and provide EDA. Provide illustration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Application of Proximity (Distance Analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for correlation. Provide illustration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start off the distance analysis, we look at various correlations to see the relationship of income and expenditures to each other, and to each of their sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_expenditure_dataframe = imputted_column_13[['Hhld, Income, Total', 'Hhld, Expenditures, Total']]\n",
    "income_expenditure_corr = income_expenditure_dataframe.corr(method='pearson')\n",
    "plt.figure(figsize=(20,10), dpi = 500)\n",
    "sns.heatmap(income_expenditure_corr,annot=True,fmt=\".2f\", linewidth=.5, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heatmap says that when income increases, expenditures slightly decreases. But overall, the two variables are highly correlated to each other, meaning that households are more likely to spend much of what they earn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now correlate income and expencitures with the various sources found in the dataset.\n",
    "Income will be correlated to monetary sources while expenditures will be correlated to various expenses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monetary_columns = [\n",
    "    'Salaries/Wages from Regular Employment',\n",
    "    'Salaries/Wages from Seasonal Employment',\n",
    "    'Net Share of Crops, Fruits, etc. (Tot. Net Value of Share)',\n",
    "    'Cash Receipts, Support, etc. from Abroad',\n",
    "    'Cash Receipts, Support, etc. from Domestic Source',\n",
    "    'Rentals Received from Non-Agri Lands, etc.',\n",
    "    'Pension and Retirement Benefits',\n",
    "    'Dividends from Investment',\n",
    "    'Other Sources of Income NEC',\n",
    "    'Family Sustenance Activities',\n",
    "    'Total Received as Gifts',\n",
    "    'Crop Farming and Gardening',\n",
    "    'Livestock and Poultry Raising',\n",
    "    'Fishing',\n",
    "    'Forestry and Hunting',\n",
    "    'Wholesale and Retail',\n",
    "    'Manufacturing',\n",
    "    'Transportation, Storage Services',\n",
    "    'Entrep. Activities NEC',\n",
    "    'Entrep. Activities NEC.1',\n",
    "    'Entrep. Activities NEC.2',\n",
    "]\n",
    "\n",
    "cost_columns = [\n",
    "    'Cereal and Cereal Preparations (Total)',\n",
    "    'Meat and Meat Preparations',\n",
    "    'Fish and Marine Products (Total)',\n",
    "    'Dairy Products and Eggs (Total)',\n",
    "    'Oils and Fats (Total)',\n",
    "    'Fruits and Vegetables',\n",
    "    'Vegetables (Total)',\n",
    "    'Sugar, Jam and Honey (Total)',\n",
    "    'Food Not Elsewhere Classified (Total)',\n",
    "    'Fruit and vegetable juices',\n",
    "    'Coffee, Cocoa and Tea (Total)',\n",
    "    'Tea (total)  expenditure',\n",
    "    'Cocoa (total)  expenditure',\n",
    "    'Main Source of Water Supply (2nd visit only)',\n",
    "    'Softdrinks',\n",
    "    'Other Non Alcoholic Beverages',\n",
    "    'Alcoholic Beverages (Total)',\n",
    "    'Tobacco (Total)',\n",
    "    'Other Vegetables (Total)',\n",
    "    'Services_Primary_Goods',\n",
    "    'Alcohol Procduction Services',\n",
    "    'Food Regularly Consumed Outside The Home (Total)',\n",
    "    'Clothing, Footwear and Other Wear',\n",
    "    'Housing and water (Total)',\n",
    "    'Actual House Rent',\n",
    "    'Furnishings, Household Equipment & Routine Household Mainte',\n",
    "    'Health (Total)',\n",
    "    'Transportation (Total)',\n",
    "    'Communication (Total)',\n",
    "    'Recreation and Culture (Total)',\n",
    "    'Education (Total)',\n",
    "    'Insurance',\n",
    "    'Miscellaneous Goods and Services (Total)',\n",
    "    'Durable Furniture',\n",
    "    'Special Family Occasion',\n",
    "    'Other Expenditure (inc. Value Consumed, Losses)',\n",
    "    'Accomodation Services',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a smoother heatmap, all similar columns will be combined to a category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monetary_columns.append('Household ID')\n",
    "income_dataframe = imputted_column_13[monetary_columns]\n",
    "\n",
    "# Combine similar columns to reduce dimensionality\n",
    "income_dataframe['Salaries/Wages'] = income_dataframe['Salaries/Wages from Regular Employment'] + income_dataframe['Salaries/Wages from Seasonal Employment']\n",
    "income_dataframe['Cash Receipts'] = income_dataframe['Cash Receipts, Support, etc. from Abroad'] + income_dataframe['Cash Receipts, Support, etc. from Domestic Source']\n",
    "income_dataframe['Farming'] = income_dataframe['Crop Farming and Gardening'] + income_dataframe['Net Share of Crops, Fruits, etc. (Tot. Net Value of Share)']\n",
    "income_dataframe['Logistics and Manufacturing'] = income_dataframe['Wholesale and Retail'] + income_dataframe['Transportation, Storage Services'] + income_dataframe['Manufacturing']\n",
    "income_dataframe['Entrep. Activities'] = income_dataframe['Entrep. Activities NEC'] + income_dataframe['Entrep. Activities NEC.1'] + income_dataframe['Entrep. Activities NEC.2']\n",
    "income_dataframe['Passive Income'] = income_dataframe['Total Received as Gifts'] + income_dataframe['Family Sustenance Activities'] + income_dataframe['Pension and Retirement Benefits'] + income_dataframe['Dividends from Investment'] + income_dataframe['Rentals Received from Non-Agri Lands, etc.']\n",
    "income_dataframe['Livestocks'] = income_dataframe['Livestock and Poultry Raising'] + income_dataframe['Fishing'] + income_dataframe['Forestry and Hunting']\n",
    "income_dataframe['Other Income NEC'] = income_dataframe['Other Sources of Income NEC']\n",
    "\n",
    "income_dataframe = income_dataframe.set_index(\"Household ID\")\n",
    "monetary_columns.pop(monetary_columns.index('Household ID'))\n",
    "# Drop the original columns\n",
    "income_dataframe.drop(columns=monetary_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_corr = income_dataframe.corr(method='pearson')\n",
    "plt.figure(figsize=(20,10), dpi = 500)\n",
    "sns.heatmap(income_corr,annot=True,fmt=\".2f\", linewidth=.5, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the heatmap above, all monetary have weak correlations, this means that monetary sources are independent with little to no dependence. The negative correlations also suggests that some monetary streams are acting as substitute to other monetary sources. If observed closely, it can be seen that cash receipts and passive income had the highest correlation of 0.12. This may mean that some individuals who's monetary sources are passive incomes, are also receiving cash rceipts or monetary support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_columns.append('Household ID')\n",
    "expenditure_dataframe = imputted_column_13[cost_columns]\n",
    "\n",
    "expenditure_dataframe['Processed Foods'] = expenditure_dataframe['Cereal and Cereal Preparations (Total)'] + expenditure_dataframe['Sugar, Jam and Honey (Total)'] + expenditure_dataframe['Softdrinks'] + expenditure_dataframe['Oils and Fats (Total)']\n",
    "expenditure_dataframe['Non-Processed Foods'] = expenditure_dataframe['Meat and Meat Preparations'] + expenditure_dataframe['Fish and Marine Products (Total)'] + expenditure_dataframe['Dairy Products and Eggs (Total)']\n",
    "expenditure_dataframe['Other Foods'] = expenditure_dataframe['Food Not Elsewhere Classified (Total)'] + expenditure_dataframe['Food Regularly Consumed Outside The Home (Total)']\n",
    "expenditure_dataframe['Fruits and Vegetables and Juices'] = expenditure_dataframe['Fruits and Vegetables'] + expenditure_dataframe['Vegetables (Total)'] + expenditure_dataframe['Fruit and vegetable juices'] + expenditure_dataframe['Other Vegetables (Total)']\n",
    "expenditure_dataframe['Non-Alcoholic Beverages'] = expenditure_dataframe['Coffee, Cocoa and Tea (Total)'] + expenditure_dataframe['Tea (total)  expenditure'] + expenditure_dataframe['Cocoa (total)  expenditure'] + expenditure_dataframe['Other Non Alcoholic Beverages']\n",
    "expenditure_dataframe['Non-Essential Expenditures'] = expenditure_dataframe['Alcoholic Beverages (Total)'] + expenditure_dataframe['Tobacco (Total)'] \n",
    "expenditure_dataframe['Services and Primary Goods'] = expenditure_dataframe['Services_Primary_Goods'] + expenditure_dataframe['Main Source of Water Supply (2nd visit only)'] + expenditure_dataframe['Accomodation Services'] + expenditure_dataframe['Alcohol Procduction Services']\n",
    "expenditure_dataframe['Miscellaneous Expenditures'] = expenditure_dataframe['Miscellaneous Goods and Services (Total)'] + expenditure_dataframe['Durable Furniture'] + expenditure_dataframe['Special Family Occasion']\n",
    "expenditure_dataframe['Non-Food Essential Expenditures'] = expenditure_dataframe['Clothing, Footwear and Other Wear'] + expenditure_dataframe['Housing and water (Total)'] + expenditure_dataframe['Actual House Rent'] + expenditure_dataframe['Furnishings, Household Equipment & Routine Household Mainte'] + expenditure_dataframe['Health (Total)']+ expenditure_dataframe['Transportation (Total)'] + expenditure_dataframe['Communication (Total)'] + expenditure_dataframe['Recreation and Culture (Total)'] + expenditure_dataframe['Education (Total)'] + expenditure_dataframe['Insurance']\n",
    "expenditure_dataframe['Other Expenditure NEC'] = expenditure_dataframe['Other Expenditure (inc. Value Consumed, Losses)']\n",
    "\n",
    "expenditure_dataframe = expenditure_dataframe.set_index(\"Household ID\")\n",
    "cost_columns.pop(cost_columns.index('Household ID'))\n",
    "expenditure_dataframe.drop(columns=cost_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditure_corr = expenditure_dataframe.corr(method='pearson')\n",
    "plt.figure(figsize=(20,10), dpi = 500)\n",
    "sns.heatmap(expenditure_corr,annot=True,fmt=\".2f\", linewidth=.5, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this heatmap, it is observed that Non-Processed FOod had the highest correlation of 0.54, this suggests that households that prioritizes non=processed foods also tends to buy more fruits, vegetables, and juices. This could mean that these households has a preference for fresh food options. It's also observed that households that has significant Non-Food Essential Expenditures have high correlations with Non-Processed, Fruits and Fegetables and Juices, and Other Foods compared with Processed Foods. This means that these households prioritizes fresh food options. It is also observed that Non-Essential Expenditures had low correlation with essential catgories like food, this suuggests that housesholds that spend on non-essential expenditures are doing so out of discretionary income rather than necessity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge income and expenditure dataframes\n",
    "income_expenditure_df = income_dataframe.join(expenditure_dataframe, how=\"inner\")\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = income_expenditure_df.corr()\n",
    "\n",
    "correlation_subset = correlation_matrix.iloc[0:8, 8:17]\n",
    "\n",
    "# Display the correlation heatmap\n",
    "plt.figure(figsize=(20, 10), dpi=500)\n",
    "sns.heatmap(correlation_subset, annot=True, fmt=\".2f\", linewidth=.5, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this heatmap correlating the monetary sources with expenditures, we can gain 3 major insights:\n",
    "\n",
    "1. Salaries/Wages are the primary determining factor in terms of expenditure\n",
    "    - Hoeseholds' that have salary/wages as their main source of income are morelikely to spend on a variety of expenditures (services, food, essential goods, and non-essential goods) likely because they have more disposable income to diversify their spending and because wages are easily accountable, they can support both their basic needs and discretionary spending.\n",
    "    - These households are also the highest spender on Miscellaneous and Non-Essential expenditures compared to other income sources. This is likely because they have a stable source of income thus allowing more leeway in term of their spending.\n",
    "2. Farming and Livestock monetary sources are self sufficient\n",
    "    - Hoesedolds' that earns their keep from farming and livestock have weak correlation with most of the expenditure categories likely because they consume what they produce, thus reducing their need to purchase foods. Another reason is that their source of income are seasonal and unpredictable, thus requiring them to be cautios on their spending.\n",
    "    - Despite their low spending, they have negative correlation with Non-Food Essential Expenditures likely becuase of abused selling price of their priducts.\n",
    "3. Logistics, Manufacturing, Entrep. Activities, and Passive Income earners spend invests their money\n",
    "    - Households' with these sources of income tend to spend more on Non-Food Essential Expenditures, likely because the money they earn goes straight to their businesses to generate more income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate a distance matrix (e.g., Euclidean distance) for numeric data as required. Provide illustration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the computation of the distance matrix, Euclidean distance will be used to cluster households based on their income-expenditure ratio. Household Numbers provided in the dataset will be the main index of the distance matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_dataframe = imputted_column_13.copy()\n",
    "household_incomes = distance_dataframe['Hhld, Income, Total'].values\n",
    "household_expenditures = distance_dataframe['Hhld, Expenditures, Total'].values\n",
    "household_ids = distance_dataframe['Household ID'].values\n",
    "household_df = pd.DataFrame({'Total Income': household_incomes, 'Total Expenditures': household_expenditures}, index=household_ids)\n",
    "household_df.index = household_df.index.map(lambda x: f\"Household No. {x}\")\n",
    "household_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset has about 149,622 entries even without the outliers, it is essential to reduce these entries so as to preserve computational power. The challenege now lies in finding a way to reduce rows but still keeping a good representation of the data. One such way researched is the <b>Freedman-Diaconis Rule</b> of getting the optimal number of bins to group the dataset into.\n",
    "\n",
    "The <b>Freedman-Diaconis Rule</b> is a method of determining the number of bins in a histogram. It is based on the interquartile range of the data. It was devised from the Scott's Rule, obtained by asymptotically minimizing the integral mean square error of the density estimate with respect to a Gaussian reference (Markov, 2022).\n",
    "\n",
    "The <b>Freedman-Diaconis Rule</b> will be implemented by finding the optimal number of bins to group the dataset into by income and expenditure. A Strata will be created by the combining the bins of income and expenditure into a string, by which a Stratified Sampling will be implemented to gain equal representation of the data. Stratas that areless than two will be dropped.\n",
    "\n",
    "Sources\n",
    "\n",
    "1. <https://medium.com/@maxmarkovvision/optimal-number-of-bins-for-histograms-3d7c48086fde>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = household_df.shape[0]\n",
    "\n",
    "income_iqr = household_df['Total Income'].quantile(0.75) - household_df['Total Income'].quantile(0.25)\n",
    "expenditure_iqr = household_df['Total Expenditures'].quantile(0.75) - household_df['Total Expenditures'].quantile(0.25)\n",
    "\n",
    "# Implement Freedman-Diaconis Rule\n",
    "bin_width_income = 2 * income_iqr / (num_rows ** (1/3))\n",
    "bin_width_expenditure = 2 * expenditure_iqr / (num_rows ** (1/3))\n",
    "\n",
    "income_bins = int((household_df['Total Income'].max() - household_df['Total Income'].min()) / bin_width_income)\n",
    "expenditure_bins = int((household_df['Total Expenditures'].max() - household_df['Total Expenditures'].min()) / bin_width_expenditure)\n",
    "\n",
    "print(f\"Income number of bins: {income_bins}\")\n",
    "print(f\"Expenditure number of bins: {expenditure_bins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "household_df['Income Bin'] = pd.qcut(household_df['Total Income'], q=income_bins, labels=False, duplicates='drop')\n",
    "household_df['Expenditure Bin'] = pd.qcut(household_df['Total Expenditures'], q=expenditure_bins, labels=False, duplicates='drop')\n",
    "\n",
    "household_df['Strata'] = household_df['Income Bin'].astype(str) + '-' + household_df['Expenditure Bin'].astype(str)\n",
    "print(household_df['Strata'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of the data before removing rare strata:\", household_df.shape)\n",
    "strata_counts = household_df['Strata'].value_counts()\n",
    "rare_strata = strata_counts[strata_counts < 2].index\n",
    "# Drop the rare strata\n",
    "household_df = household_df[~household_df['Strata'].isin(rare_strata)]\n",
    "\n",
    "print(\"Shape of the data after removing rare strata:\", household_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now implement <b>Stratified Sampling</b> to get 5% of the data which will account for 7,434 rows for a balance of good representation of the data and a save in computational power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sampled_df, _ = train_test_split(household_df, test_size=0.95, random_state=42, stratify=household_df['Strata']) # Get 5% of the data\n",
    "\n",
    "sampled_df.drop(columns=['Income Bin', 'Expenditure Bin', 'Strata'], inplace=True)\n",
    "print('Shape of sampled data:', sampled_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Euclidean Distance is sensitive to the scale of the data, we will normalize the data using Standard Scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Scale the data for Euclidean distance\n",
    "scaled_data = StandardScaler().fit_transform(sampled_df)\n",
    "scaled_data_df = pd.DataFrame(scaled_data, columns=sampled_df.columns, index=sampled_df.index)\n",
    "scaled_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy will be used to calculate the Euclidean Distance and obtain the distance matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "euclidean_distances = pd.DataFrame(distance_matrix(scaled_data, scaled_data), index=sampled_df.index, columns=sampled_df.index)\n",
    "euclidean_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sample visualization, 10 samples will be used to create a heatmap. In this case, cooler colors means that households are closer to each other while warmer colors means that households are further away from each other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "sampled_indices = euclidean_distances.sample(n=n_samples, random_state=42).index\n",
    "euclidean_distances_sampled = euclidean_distances.loc[sampled_indices, sampled_indices]\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(euclidean_distances_sampled, cmap=\"coolwarm\", annot=False)\n",
    "plt.title(\"Euclidean Distance Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agglomerative Clustering directly works with a distance matrix as an input. We use the distance matrix of euclidean distances and form clusters based on similar household incomes and expenditures, and we add them to the sampled dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "num_clusters = 4  \n",
    "\n",
    "clustering = AgglomerativeClustering(n_clusters=num_clusters)\n",
    "cluster_labels = clustering.fit_predict(euclidean_distances)\n",
    "\n",
    "sampled_df['Cluster'] = cluster_labels\n",
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    x='Total Income', \n",
    "    y='Total Expenditures', \n",
    "    hue='Cluster', \n",
    "    palette='viridis', \n",
    "    data=sampled_df, \n",
    "    s=100\n",
    ")\n",
    "plt.title('Cluster Visualization')\n",
    "plt.xlabel('Total Income')\n",
    "plt.ylabel('Total Expenditures')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scatterplot shows the clusters formed by the agglomerative clustering. We can see that the clusters are formed by similar households. In this case, four clusters are formed.\n",
    "\n",
    "1. The 0 Cluster are households with relatively high income and high expenditures\n",
    "2. The 1 and 2 Cluster are middle of the line in terms of income and expenditures, with the 1 Cluster having less of both.\n",
    "3. The 3 Cluster are households with relatively low income and expenditures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_expenditure_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_incomes_df = imputted_column_13.copy()\n",
    "\n",
    "combined_incomes_df['Salaries/Wages'] = combined_incomes_df['Salaries/Wages from Regular Employment'] + combined_incomes_df['Salaries/Wages from Seasonal Employment']\n",
    "combined_incomes_df['Cash Receipts'] = combined_incomes_df['Cash Receipts, Support, etc. from Abroad'] + combined_incomes_df['Cash Receipts, Support, etc. from Domestic Source']\n",
    "combined_incomes_df['Farming'] = combined_incomes_df['Crop Farming and Gardening'] + combined_incomes_df['Net Share of Crops, Fruits, etc. (Tot. Net Value of Share)']\n",
    "combined_incomes_df['Logistics and Manufacturing'] = combined_incomes_df['Wholesale and Retail'] + combined_incomes_df['Transportation, Storage Services'] + combined_incomes_df['Manufacturing']\n",
    "combined_incomes_df['Entrep. Activities'] = combined_incomes_df['Entrep. Activities NEC'] + combined_incomes_df['Entrep. Activities NEC.1'] + combined_incomes_df['Entrep. Activities NEC.2']\n",
    "combined_incomes_df['Passive Income'] = combined_incomes_df['Total Received as Gifts'] + combined_incomes_df['Family Sustenance Activities'] + combined_incomes_df['Pension and Retirement Benefits'] + combined_incomes_df['Dividends from Investment'] + combined_incomes_df['Rentals Received from Non-Agri Lands, etc.']\n",
    "combined_incomes_df['Livestocks'] = combined_incomes_df['Livestock and Poultry Raising'] + combined_incomes_df['Fishing'] + combined_incomes_df['Forestry and Hunting']\n",
    "combined_incomes_df['Other Income NEC'] = combined_incomes_df['Other Sources of Income NEC']\n",
    "\n",
    "combined_incomes_df['Processed Foods'] = combined_incomes_df['Cereal and Cereal Preparations (Total)'] + combined_incomes_df['Sugar, Jam and Honey (Total)'] + combined_incomes_df['Softdrinks'] + combined_incomes_df['Oils and Fats (Total)']\n",
    "combined_incomes_df['Non-Processed Foods'] = combined_incomes_df['Meat and Meat Preparations'] + combined_incomes_df['Fish and Marine Products (Total)'] + combined_incomes_df['Dairy Products and Eggs (Total)']\n",
    "combined_incomes_df['Other Foods'] = combined_incomes_df['Food Not Elsewhere Classified (Total)'] + combined_incomes_df['Food Regularly Consumed Outside The Home (Total)']\n",
    "combined_incomes_df['Fruits and Vegetables and Juices'] = combined_incomes_df['Fruits and Vegetables'] + combined_incomes_df['Vegetables (Total)'] + combined_incomes_df['Fruit and vegetable juices'] + combined_incomes_df['Other Vegetables (Total)']\n",
    "combined_incomes_df['Non-Alcoholic Beverages'] = combined_incomes_df['Coffee, Cocoa and Tea (Total)'] + combined_incomes_df['Tea (total)  expenditure'] + combined_incomes_df['Cocoa (total)  expenditure'] + combined_incomes_df['Other Non Alcoholic Beverages']\n",
    "combined_incomes_df['Non-Essential Expenditures'] = combined_incomes_df['Alcoholic Beverages (Total)'] + combined_incomes_df['Tobacco (Total)'] \n",
    "combined_incomes_df['Services and Primary Goods'] = combined_incomes_df['Services_Primary_Goods'] + combined_incomes_df['Main Source of Water Supply (2nd visit only)'] + combined_incomes_df['Accomodation Services'] + combined_incomes_df['Alcohol Procduction Services']\n",
    "combined_incomes_df['Miscellaneous Expenditures'] = combined_incomes_df['Miscellaneous Goods and Services (Total)'] + combined_incomes_df['Durable Furniture'] + combined_incomes_df['Special Family Occasion']\n",
    "combined_incomes_df['Non-Food Essential Expenditures'] = combined_incomes_df['Clothing, Footwear and Other Wear'] + combined_incomes_df['Housing and water (Total)'] + combined_incomes_df['Actual House Rent'] + combined_incomes_df['Furnishings, Household Equipment & Routine Household Mainte'] + combined_incomes_df['Health (Total)']+ combined_incomes_df['Transportation (Total)'] + combined_incomes_df['Communication (Total)'] + combined_incomes_df['Recreation and Culture (Total)'] + combined_incomes_df['Education (Total)'] + combined_incomes_df['Insurance']\n",
    "combined_incomes_df['Other Expenditure NEC'] = combined_incomes_df['Other Expenditure (inc. Value Consumed, Losses)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_cols = ['Salaries/Wages', 'Cash Receipts', 'Farming', 'Logistics and Manufacturing', \n",
    "   'Entrep. Activities', 'Passive Income', 'Livestocks', 'Other Income NEC']\n",
    "\n",
    "expenditure_cols = ['Processed Foods',\n",
    "'Non-Processed Foods',\n",
    "'Other Foods',\n",
    "'Fruits and Vegetables and Juices',\n",
    "'Non-Alcoholic Beverages',\n",
    "'Non-Essential Expenditures',\n",
    "'Services and Primary Goods',\n",
    "'Miscellaneous Expenditures',\n",
    "'Non-Food Essential Expenditures',\n",
    "'Other Expenditure NEC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering for all income and expenditure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = income_expenditure_df[income_cols + expenditure_cols]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_cluster)\n",
    "\n",
    "# Compute distortion for different numbers of clusters\n",
    "distortions = []\n",
    "K = range(2, 11)  # Test cluster sizes from 2 to 10\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(df_scaled)\n",
    "    distortions.append(kmeans.inertia_)  # Inertia is the sum of squared distances to the nearest cluster center\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K, distortions, marker='o')\n",
    "plt.title(\"Elbow Method for Optimal k\")\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Distortion (Inertia)\")\n",
    "plt.xticks(K)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "df_cluster['Cluster'] = kmeans.fit_predict(df_scaled)\n",
    "\n",
    "# Add cluster labels back to original data\n",
    "combined_incomes_df['Cluster'] = df_cluster['Cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensions to 2D using PCA for visualization\n",
    "pca = PCA(n_components=2)\n",
    "df_pca = pca.fit_transform(df_scaled)\n",
    "df_cluster['PCA1'] = df_pca[:, 0]\n",
    "df_cluster['PCA2'] = df_pca[:, 1]\n",
    "\n",
    "# Plot clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=df_cluster['PCA1'], y=df_cluster['PCA2'], hue=df_cluster['Cluster'], palette=\"tab10\", alpha=0.7)\n",
    "plt.title(\"Household Clusters Based on Income & Expenditure\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean income & expenditure per cluster\n",
    "cluster_summary = df_cluster.groupby(\"Cluster\").mean()\n",
    "\n",
    "# Print summary\n",
    "cluster_summary[income_cols + expenditure_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering for total income and expenditures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = combined_incomes_df.copy()\n",
    "\n",
    "df_cluster.set_index('Household ID', inplace=True)\n",
    "\n",
    "cols = ['Hhld, Expenditures, Total', 'Hhld, Income, Total']\n",
    "\n",
    "df_cluster = df_cluster[cols]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_cluster)\n",
    "\n",
    "# Compute distortion for different numbers of clusters\n",
    "distortions = []\n",
    "K = range(2, 11)  # Test cluster sizes from 2 to 10\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(df_scaled)\n",
    "    distortions.append(kmeans.inertia_)  # Inertia is the sum of squared distances to the nearest cluster center\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K, distortions, marker='o')\n",
    "plt.title(\"Elbow Method for Optimal k\")\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Distortion (Inertia)\")\n",
    "plt.xticks(K)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "df_cluster['Cluster'] = kmeans.fit_predict(df_scaled)\n",
    "\n",
    "# Add cluster labels back to original data\n",
    "combined_incomes_df['Cluster'] = df_cluster['Cluster']\n",
    "\n",
    "# Plot clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=df_cluster[cols[0]], y=df_cluster[cols[1]], hue=df_cluster['Cluster'], palette=\"tab10\", alpha=0.7)\n",
    "plt.title(\"Household Clusters Based on Income & Expenditure\")\n",
    "plt.xlabel(f\"{cols[0]}\")\n",
    "plt.ylabel(f\"{cols[1]}\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()\n",
    "# Get mean income & expenditure per cluster\n",
    "cluster_summary = df_cluster.groupby(\"Cluster\").mean()\n",
    "\n",
    "# Print summary\n",
    "cluster_summary[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering for Food total amd Non-Food Essensital Expenditures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = combined_incomes_df.copy()\n",
    "\n",
    "df_cluster.set_index('Household ID', inplace=True)\n",
    "\n",
    "cols = ['Hhld, Food', 'Non-Food Essential Expenditures']\n",
    "\n",
    "df_cluster = df_cluster[cols]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_cluster)\n",
    "\n",
    "# Compute distortion for different numbers of clusters\n",
    "distortions = []\n",
    "K = range(2, 11)  # Test cluster sizes from 2 to 10\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(df_scaled)\n",
    "    distortions.append(kmeans.inertia_)  # Inertia is the sum of squared distances to the nearest cluster center\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K, distortions, marker='o')\n",
    "plt.title(\"Elbow Method for Optimal k\")\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Distortion (Inertia)\")\n",
    "plt.xticks(K)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "df_cluster['Cluster'] = kmeans.fit_predict(df_scaled)\n",
    "\n",
    "# Add cluster labels back to original data\n",
    "combined_incomes_df['Cluster'] = df_cluster['Cluster']\n",
    "\n",
    "# Plot clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=df_cluster[cols[0]], y=df_cluster[cols[1]], hue=df_cluster['Cluster'], palette=\"tab10\", alpha=0.7)\n",
    "plt.title(\"Household Clusters Based on Total Food anf Non-Food Essential Expenditures\")\n",
    "plt.xlabel(f\"{cols[0]}\")\n",
    "plt.ylabel(f\"{cols[1]}\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()\n",
    "# Get mean income & expenditure per cluster\n",
    "cluster_summary = df_cluster.groupby(\"Cluster\").mean()\n",
    "\n",
    "# Print summary\n",
    "cluster_summary[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_expenditure_low_income_df = combined_incomes_df[combined_incomes_df['Hhld, Income, Total'] < combined_incomes_df['Hhld, Expenditures, Total']]\n",
    "high_expenditure_low_income_df = high_expenditure_low_income_df[income_cols + expenditure_cols + ['Household ID']]\n",
    "high_expenditure_low_income_df.set_index('Household ID', inplace=True)\n",
    "\n",
    "high_expenditure_low_income_corr = high_expenditure_low_income_df.corr()\n",
    "\n",
    "correlation_subset = high_expenditure_low_income_corr.iloc[0:8, 8:17]\n",
    "\n",
    "plt.figure(figsize=(20,10), dpi = 500)\n",
    "plt.title(\"Correlation Heatmap for High Expenditure Low Income Households\")\n",
    "sns.heatmap(correlation_subset,annot=True,fmt=\".2f\", linewidth=.5, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_expenditure_low_income_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = high_expenditure_low_income_df.copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_cluster)\n",
    "\n",
    "# Compute distortion for different numbers of clusters\n",
    "distortions = []\n",
    "K = range(2, 11)  # Test cluster sizes from 2 to 10\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(df_scaled)\n",
    "    distortions.append(kmeans.inertia_)  # Inertia is the sum of squared distances to the nearest cluster center\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K, distortions, marker='o')\n",
    "plt.title(\"Elbow Method for Optimal k\")\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Distortion (Inertia)\")\n",
    "plt.xticks(K)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=8, random_state=42)\n",
    "df_cluster['Cluster'] = kmeans.fit_predict(df_scaled)\n",
    "\n",
    "# Add cluster labels back to original data\n",
    "combined_incomes_df['Cluster'] = df_cluster['Cluster']\n",
    "\n",
    "# Get mean income & expenditure per cluster\n",
    "cluster_summary = df_cluster.groupby(\"Cluster\").mean()\n",
    "\n",
    "# Plot clusters in a heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(cluster_summary, cmap=\"coolwarm\", annot=False)\n",
    "plt.title(\"Cluster-wise Income and Expenditure Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_percentage = cluster_summary.apply(lambda x: x / x.sum(), axis=1)\n",
    "df_percentage[income_cols].T.plot(kind=\"bar\", stacked=True, figsize=(14, 6), colormap=\"tab10\")\n",
    "plt.title(\"Proportion of Income Categories per Cluster\")\n",
    "plt.xlabel(\"Income Categories\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(title=\"Clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_percentage = cluster_summary.apply(lambda x: x / x.sum(), axis=1)\n",
    "df_percentage[expenditure_cols].T.plot(kind=\"bar\", stacked=True, figsize=(14, 6), colormap=\"tab10\")\n",
    "plt.title(\"Proportion of Expenditure Categories per Cluster\")\n",
    "plt.xlabel(\"Expenditure Categories\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(title=\"Clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farmer_df = combined_incomes_df[combined_incomes_df['Farming'] > 0]\n",
    "farmer_df.set_index('Household ID', inplace=True)\n",
    "farmer_df = farmer_df[cost_columns]\n",
    "total_spending = farmer_df.sum().sort_values(ascending=False)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "total_spending.plot(kind='bar', color='teal')\n",
    "plt.title(\"Total Expenditure per Category (Farmers)\")\n",
    "plt.ylabel(\"Total Spending\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farmer_df = combined_incomes_df[combined_incomes_df['Livestocks'] > 0]\n",
    "farmer_df.set_index('Household ID', inplace=True)\n",
    "farmer_df = farmer_df[cost_columns]\n",
    "total_spending = farmer_df.sum().sort_values(ascending=False)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "total_spending.plot(kind='bar', color='teal')\n",
    "plt.title(\"Total Expenditure per Category (Livestocks)\")\n",
    "plt.ylabel(\"Total Spending\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Data Mining: Association Rule Mining\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If needed, transform the dataset (one-hot encoding) and apply the Apriori algorithm to extract association rules.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
