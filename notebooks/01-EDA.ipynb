{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Import & Exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the large dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "fies_df = pd.read_csv('../datasets/fies_2023_volume1_494887610821.csv')\n",
    "fies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Identifying Data and Attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List all column types and data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_and_datatypes = pd.DataFrame({\n",
    "    'Data Type': fies_df.dtypes\n",
    "}, index=fies_df.columns)\n",
    "# Display all rows of the DataFrame\n",
    "for index, row in columns_and_datatypes.iterrows():\n",
    "    print(f\"{index}: {row['Data Type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All columns seem to be either an integer or a float value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to remove \"\" from column names\n",
    "fies_df.columns = fies_df.columns.str.strip('\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Determining the Type of Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if columns are numerical, categorical, or mixed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_check = pd.DataFrame({\n",
    "    'Column Type': None\n",
    "}, index=fies_df.columns)\n",
    "\n",
    "for column in fies_df.columns:\n",
    "    column_check['Column Type'] = pd.api.types.infer_dtype(fies_df[column])\n",
    "\n",
    "for index, row in column_check.iterrows():\n",
    "    print(f\"{index}: {row['Column Type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the columns seem to be numerical. However, an excel file that contains all metadata on what certain numbers in certain columns mean is provided by the PSA, (ex. Region Number Equivalents).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Data Dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fies_column_descriptions = {\n",
    "#     'RDMD_ID': 'Unique identifier for the record',\n",
    "#     'Region': 'Region code',\n",
    "#     'Province': 'Province code',\n",
    "#     'Household ID': 'Unique household identifier',\n",
    "#     'RECODED PROVINCE': 'Recoded province information',\n",
    "#     'Family Size': 'Number of people in the household',\n",
    "#     'Salaries/Wages from Regular Employment': 'Income from regular employment',\n",
    "#     'Salaries/Wages from Seasonal Employment': 'Income from seasonal employment',\n",
    "#     'Income from Salaries and Wages': 'Total income from salaries and wages',\n",
    "#     'Net Share of Crops, Fruits, etc. (Tot. Net Value of Share)': 'Net value from crop and fruit share',\n",
    "#     'Cash Receipts, Support, etc. from Abroad': 'Cash support received from abroad',\n",
    "#     'Cash Receipts, Support, etc. from Domestic Source': 'Cash support received domestically',\n",
    "#     'Rentals Received from Non-Agri Lands, etc.': 'Income from land rentals (non-agricultural)',\n",
    "#     'Unnamed: 13': 'Unknown or unnamed column',\n",
    "#     'Pension and Retirement Benefits': 'Income from pensions and retirement',\n",
    "#     'Dividends from Investment': 'Income from dividends',\n",
    "#     'Other Sources of Income NEC': 'Other sources of income not elsewhere classified',\n",
    "#     'Family Sustenance Activities': 'Income from family sustenance activities',\n",
    "#     'Total Received as Gifts': 'Total gifts received by the household',\n",
    "#     'Crop Farming and Gardening': 'Income from crop farming and gardening',\n",
    "#     'Livestock and Poultry Raising': 'Income from livestock and poultry raising',\n",
    "#     'Fishing': 'Income from fishing activities',\n",
    "#     'Forestry and Hunting': 'Income from forestry and hunting',\n",
    "#     'Wholesale and Retail': 'Income from wholesale and retail business',\n",
    "#     'Manufacturing': 'Income from manufacturing activities',\n",
    "#     'Transportation, Storage Services': 'Income from transportation and storage services',\n",
    "#     'Entrep. Activities NEC': 'Income from entrepreneurial activities (not elsewhere classified)',\n",
    "#     'Entrep. Activities NEC.1': 'Income from entrepreneurial activities (additional category 1)',\n",
    "#     'Entrep. Activities NEC.2': 'Income from entrepreneurial activities (additional category 2)',\n",
    "#     'Hhld, Income from Entrepreneurial Activities, Total': 'Total household income from entrepreneurial activities',\n",
    "#     'Losses from EA': 'Losses from entrepreneurial activities',\n",
    "#     'Cereal and Cereal Preparations (Total)': 'Expenditure on cereals and cereal preparations',\n",
    "#     'Meat and Meat Preparations': 'Expenditure on meat and meat preparations',\n",
    "#     'Fish and Marine Products (Total)': 'Expenditure on fish and marine products',\n",
    "#     'Dairy Products and Eggs (Total)': 'Expenditure on dairy products and eggs',\n",
    "#     'Oils and Fats (Total)': 'Expenditure on oils and fats',\n",
    "#     'Fruits and Vegetables': 'Expenditure on fruits and vegetables',\n",
    "#     'Vegetables (Total)': 'Expenditure on vegetables',\n",
    "#     'Sugar, Jam and Honey (Total)': 'Expenditure on sugar, jam, and honey',\n",
    "#     'Food Not Elsewhere Classified (Total)': 'Expenditure on other food items',\n",
    "#     'Fruit and vegetable juices': 'Expenditure on fruit and vegetable juices',\n",
    "#     'Coffee, Cocoa and Tea (Total)': 'Expenditure on coffee, cocoa, and tea',\n",
    "#     'Tea (total)  expenditure': 'Expenditure on tea',\n",
    "#     'Cocoa (total)  expenditure': 'Expenditure on cocoa',\n",
    "#     'Main Source of Water Supply (2nd visit only)': 'Main source of water supply (second visit)',\n",
    "#     'Softdrinks': 'Expenditure on soft drinks',\n",
    "#     'Other Non Alcoholic Beverages': 'Expenditure on other non-alcoholic beverages',\n",
    "#     'Alcoholic Beverages (Total)': 'Expenditure on alcoholic beverages',\n",
    "#     'Tobacco (Total)': 'Expenditure on tobacco products',\n",
    "#     'Other Vegetables (Total)': 'Expenditure on other types of vegetables',\n",
    "#     'Services_Primary_Goods': 'Expenditure on services and primary goods',\n",
    "#     'Alcohol Procduction Services': 'Expenditure on alcohol production services',\n",
    "#     'Total Food Consumed at Home (Total)': 'Total food consumed at home',\n",
    "#     'Food Regularly Consumed Outside The Home (Total)': 'Food consumed outside the home',\n",
    "#     'Hhld, Food': 'Household expenditure on food',\n",
    "#     'Clothing, Footwear and Other Wear': 'Expenditure on clothing, footwear, and other wear',\n",
    "#     'Housing and water (Total)': 'Expenditure on housing and water',\n",
    "#     'Actual House Rent': 'Expenditure on actual house rent',\n",
    "#     'Imputed House Rental Value': 'Imputed value of house rental',\n",
    "#     'Imputed Housing Benefit Rental Value': 'Imputed value of housing benefit rental',\n",
    "#     'House Rent/Rental Value': 'Expenditure on house rent/rental value',\n",
    "#     'Furnishings, Household Equipment & Routine Household Mainte': 'Expenditure on furnishings and household equipment',\n",
    "#     'Health (Total)': 'Expenditure on health services and products',\n",
    "#     'Transportation (Total)': 'Expenditure on transportation',\n",
    "#     'Communication (Total)': 'Expenditure on communication services',\n",
    "#     'Recreation and Culture (Total)': 'Expenditure on recreation and culture',\n",
    "#     'Education (Total)': 'Expenditure on education',\n",
    "#     'Insurance': 'Expenditure on insurance',\n",
    "#     'Miscellaneous Goods and Services (Total)': 'Expenditure on miscellaneous goods and services',\n",
    "#     'Durable Furniture': 'Expenditure on durable furniture',\n",
    "#     'Special Family Occasion': 'Expenditure on special family occasions',\n",
    "#     'Other Expenditure (inc. Value Consumed, Losses)': 'Other expenditures including losses',\n",
    "#     'Other Disbursements': 'Other household disbursements',\n",
    "#     'Accomodation Services': 'Expenditure on accommodation services',\n",
    "#     'Total Non-Food Expenditure': 'Total non-food expenditure',\n",
    "#     'Hhld, Income, Total': 'Total household income',\n",
    "#     'Hhld, Expenditures, Total': 'Total household expenditures',\n",
    "#     'Total Household Disbursements': 'Total household disbursements',\n",
    "#     'Other Receipts': 'Other household receipts',\n",
    "#     'Total Receipts': 'Total receipts',\n",
    "#     'Psu (Recode)': 'Primary Sampling Unit (recoded)',\n",
    "#     'Raising Factor': 'Raising factor for survey results',\n",
    "#     'Final Population Weights': 'Final weights for population data',\n",
    "#     'Urban / Rural': 'Urban or rural classification',\n",
    "#     'Per Capita Income': 'Household per capita income',\n",
    "#     'NPCINC': 'National per capita income',\n",
    "#     'RPCINC': 'Regional per capita income',\n",
    "#     'Per Capita Income Decile (Province)': 'Per capita income decile in the province',\n",
    "#     'pPCINC': 'Provincial per capita income decile',\n",
    "#     'Per Capita Income Decile (Region with Negros Island Region (NIR))': 'Per capita income decile (region with NIR)',\n",
    "#     'Region (with NIR)': 'Region code including NIR'\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fies_derivations = {\n",
    "#     'Total Receipts': 'Total Household Income + Other Receipts',\n",
    "#     'Hhld, Income, Total': 'Net Share of Crops, Fruits, etc. + Cash Receipts, Support, etc. from Abroad + Cash Receipts, Support, etc. from Domestic Source + Unnamed + Pension and Retirement Benefits + Dividends from Investment + Other Sources of Income NEC + Family Sustenance Activities + Total Received as Gifts + Household, Income from Entrep Activities, Total + Imputed House Rental Value',\n",
    "#     'Hhld, Income from Entrepreneurial Activities, Total': 'Crop Farming and Gardening + Livestock and Poultry Raising + Fishing + Forestry and Hunting + Wholesale and Retail + Manufacturing + Transportation, Storage Services + Entrep. Activities NEC + Entrep. Activities NEC 1 + Entrep. Activities NEC 2',\n",
    "#     'Total Household Disbursements': 'Total Household Expenditure + Other Disbursements',\n",
    "#     'Hhld, Expenditures, Total': 'Household Food + Total Non-Food Expenditure',\n",
    "#     'Hhld, Food': 'Total Food Consumed at Home + Food Regularly Consumed Outside The Home',\n",
    "#     'Total Food Consumed at Home (Total)': 'Cereal and Cereal Preparations + Meat and Meat Preparations + Fish and Marine Products + Dairy and Eggs + Oils and Fats + Fruits and Vegetables + Vegetables + Sugar, jam and Honey + Food Not Elsewhere Classified + Fruit and Vegetable Juices + Coffee, Cocoa and Tea + Tea + Cocoa + Main Source of Water Supply + Softdrinks + Other Non Alcoholic Beverages',\n",
    "#     'Total Non-Food Expenditure': 'Alcoholic Beverages + Tobacco + Other Vegetables + Services_Primary_Goods + Alcoholic Production Services + Housing and water (Total) + Furnishings, Household Equipment & Routine Household Maintenance + Health + Transportation + Communication + Recreation and Culture + Education + Insurance + Miscellaneous Goods and Services + Durable Furniture + Special Family Occasion + Other Expenditure + Accommodation Services + Clothing, Footwear and Other Wear',\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fies_volume1_data_dict = pd.DataFrame({\n",
    "#     'Column Name': fies_df.columns,\n",
    "#     'Data Type': fies_df.dtypes,\n",
    "#     'Non-Null Count': fies_df.notnull().sum(),\n",
    "#     'Unique Values': fies_df.nunique(),\n",
    "#     'Description': [fies_column_descriptions.get(col, 'No desciption available') for col in fies_df.columns],\n",
    "#     'Derivations from other columns': [fies_derivations.get(col, '') for col in fies_df.columns]\n",
    "# })\n",
    "# fies_volume1_data_dict.to_csv('../fies_volume1_data_dict.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Quality and Assessment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing values, duplicates, outliers, and wrong data.<b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_rows = fies_df.shape[0]\n",
    "\n",
    "print(f\"Number of rows: {number_of_rows}\")\n",
    "\n",
    "removed_duplicates = fies_df.copy()\n",
    "removed_duplicates.drop_duplicates(inplace=True)\n",
    "\n",
    "print(f\"Number of rows after dropping duplicates: {removed_duplicates.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicates are found.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data dictionary, the Total Household Disbursements column is the only one with an object datatype, suggesting mixed values of numbers, strings, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in removed_duplicates.columns:\n",
    "    if removed_duplicates[column].isnull().any():\n",
    "        print(f\"Column {column} has missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block above does not show any null values initially, therefore there is the possibility of data with only whitespace values. The code below will strip all whitespaces\n",
    "to know the true number of missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a value is whitespace or empty\n",
    "def has_whitespace(val):\n",
    "    return isinstance(val, str) and val.strip() == ''\n",
    "\n",
    "whitespace_rows = removed_duplicates.map(has_whitespace).any(axis=1)\n",
    "\n",
    "whitespace_count = whitespace_rows.sum()\n",
    "\n",
    "print(f\"Number of rows with whitespace: {whitespace_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are whitespaces. Whitespaces could mean that the value for that data is zero. Therefore, a check must be made to ensure that there are zeroes in the dataset as well to know that whitespaces and zeroes are equivalent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(removed_duplicates['Total Household Disbursements'].value_counts().where(removed_duplicates['Total Household Disbursements'] == 0, 1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we detect potential outliers using statistical methods.\n",
    "The main columns to look at are the Total Household Income and Total Household Expenditure columns..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_mean = removed_duplicates['Hhld, Income, Total'].mean()\n",
    "income_median = removed_duplicates['Hhld, Income, Total'].median()\n",
    "income_std = removed_duplicates['Hhld, Income, Total'].std()\n",
    "\n",
    "print(f\"Income Mean: {income_mean}\")\n",
    "print(f\"Income Median: {income_median}\")\n",
    "print(f\"Income Standard Deviation: {income_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditure_mean = removed_duplicates['Hhld, Expenditures, Total'].mean()\n",
    "expenditure_median = removed_duplicates['Hhld, Expenditures, Total'].median()\n",
    "expenditure_std = removed_duplicates['Hhld, Expenditures, Total'].std()\n",
    "\n",
    "print(f\"Expenditure Mean: {expenditure_mean}\")\n",
    "print(f\"Expenditure Median: {expenditure_median}\")\n",
    "print(f\"Expenditure Standard Deviation: {expenditure_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results, the mean for the income and expenditure columns are quite large. To see more, a boxplot can be used to visualize the distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.boxplot(removed_duplicates['Hhld, Income, Total'])\n",
    "plt.title('Boxplot of Income')\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(removed_duplicates['Hhld, Expenditures, Total'])\n",
    "plt.title('Boxplot of Expenditures')\n",
    "plt.xlabel('Expenditures')\n",
    "plt.ylabel('Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.scatter(removed_duplicates['Hhld, Income, Total'], removed_duplicates['Hhld, Expenditures, Total'])\n",
    "ax.set_xlabel('Income')\n",
    "ax.set_ylabel('Expenditure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the boxplots and scatter plots, there defenitely are high-value outliers for both Income and Expenditure, and from the column derivations, this also means that by addressing only these two columns, the rest of the outlier columns can be addressed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute, discretize and data wrangling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are zeroes present, the Total Household Disbursements column must be addressed. Upon inspection, Total Household Disbursements can be imputed from the sum of Hhld, Expenditures, Total and Other Disbursements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_null = removed_duplicates.copy()\n",
    "removed_null.loc[whitespace_rows, 'Total Household Disbursements'] = removed_null.loc[whitespace_rows, \n",
    "                                                                            'Hhld, Expenditures, Total'] + removed_null.loc[whitespace_rows, 'Other Disbursements']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-check for missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitespace_rows = removed_null.map(has_whitespace).any(axis=1)\n",
    "whitespace_count = whitespace_rows.sum()\n",
    "print(f\"Number of rows with whitespace: {whitespace_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now address the outliers using the IQR method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_Q1 = removed_null['Hhld, Income, Total'].quantile(0.25)\n",
    "income_Q3 = removed_null['Hhld, Income, Total'].quantile(0.75)\n",
    "income_IQR = income_Q3 - income_Q1\n",
    "print(f\"Income Q1: {income_Q1}\")\n",
    "print(f\"Income Q3: {income_Q3}\")\n",
    "print(f\"Income IQR: {income_IQR}\")\n",
    "\n",
    "expenditure_Q1 = removed_null['Hhld, Expenditures, Total'].quantile(0.25)\n",
    "expenditure_Q3 = removed_null['Hhld, Expenditures, Total'].quantile(0.75)\n",
    "expenditure_IQR = expenditure_Q3 - expenditure_Q1\n",
    "print(f\"Expenditure Q1: {expenditure_Q1}\")\n",
    "print(f\"Expenditure Q3: {expenditure_Q3}\")\n",
    "print(f\"Expenditure IQR: {expenditure_IQR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Income\n",
    "removed_outliers = removed_null.copy()\n",
    "print('Shape before removing outliers:', removed_outliers.shape)\n",
    "lower_bound_income = income_Q1 - 1.5 * income_IQR\n",
    "upper_bound_income = income_Q3 + 1.5 * income_IQR\n",
    "upper_income = np.where(removed_outliers['Hhld, Income, Total'] >= upper_bound_income)[0]\n",
    "lower_income = np.where(removed_outliers['Hhld, Income, Total'] <= lower_bound_income)[0]\n",
    "\n",
    "removed_outliers.drop(index=upper_income, inplace=True)\n",
    "removed_outliers.drop(index=lower_income, inplace=True)\n",
    "print('Shape after removing outliers for Income:', removed_outliers.shape)\n",
    "\n",
    "# Expenditure\n",
    "lower_bound_expenditure = expenditure_Q1 - 1.5 * expenditure_IQR\n",
    "upper_bound_expenditure = expenditure_Q3 + 1.5 * expenditure_IQR\n",
    "removed_outliers.reset_index(drop=True, inplace=True)\n",
    "upper_expenditure = np.where(removed_outliers['Hhld, Expenditures, Total'] >= upper_bound_expenditure)[0]\n",
    "lower_expenditure = np.where(removed_outliers['Hhld, Expenditures, Total'] <= lower_bound_expenditure)[0]\n",
    "\n",
    "removed_outliers.drop(index=upper_expenditure, inplace=True)\n",
    "removed_outliers.drop(index=lower_expenditure, inplace=True)\n",
    "print('Shape after removing outliers for Expenditure:', removed_outliers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to check using the same methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_mean = removed_outliers['Hhld, Income, Total'].mean()\n",
    "income_median = removed_outliers['Hhld, Income, Total'].median()\n",
    "income_std = removed_outliers['Hhld, Income, Total'].std()\n",
    "\n",
    "print(f\"Income Mean: {income_mean}\")\n",
    "print(f\"Income Median: {income_median}\")\n",
    "print(f\"Income Standard Deviation: {income_std}\")\n",
    "\n",
    "expenditure_mean = removed_outliers['Hhld, Expenditures, Total'].mean()\n",
    "expenditure_median = removed_outliers['Hhld, Expenditures, Total'].median()\n",
    "expenditure_std = removed_outliers['Hhld, Expenditures, Total'].std()\n",
    "\n",
    "print(f\"Expenditure Mean: {expenditure_mean}\")\n",
    "print(f\"Expenditure Median: {expenditure_median}\")\n",
    "print(f\"Expenditure Standard Deviation: {expenditure_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(removed_outliers['Hhld, Income, Total'])\n",
    "plt.title('Boxplot of Income')\n",
    "plt.xlabel('Income')\n",
    "plt.ylabel('Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(removed_outliers['Hhld, Expenditures, Total'])\n",
    "plt.title('Boxplot of Expenditures')\n",
    "plt.xlabel('Expenditures')\n",
    "plt.ylabel('Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.scatter(removed_outliers['Hhld, Income, Total'], removed_outliers['Hhld, Expenditures, Total'])\n",
    "ax.set_xlabel('Income')\n",
    "ax.set_ylabel('Expenditure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outliers are now removed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a column named Unnamed_13 in the dataset. We opted to total the unnamed column and other sources of income NEC because the unnamed column contributes to the total income of the household as some of the total income were inaccurate if the unnamed column wans't included\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputted_column_13 = removed_outliers.copy()\n",
    "imputted_column_13['Other Sources of Income NEC'] = imputted_column_13['Other Sources of Income NEC'] + imputted_column_13['Unnamed: 13']\n",
    "print(\"Number of columns before dropping:\", imputted_column_13.shape[1])\n",
    "imputted_column_13.drop(columns=['Unnamed: 13'], inplace=True)\n",
    "print(\"Number of columns after dropping:\", imputted_column_13.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Quantitative Statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate statistics and provide EDA. Provide illustration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Application of Proximity (Distance Analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for correlation. Provide illustration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start off the distance analysis, we look at various correlations to see the relationship of income and expenditures to each other, and to each of their sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# income_expenditure_dataframe = imputted_column_13[['Hhld, Income, Total', 'Hhld, Expenditures, Total']]\n",
    "# income_expenditure_corr = income_expenditure_dataframe.corr(method='pearson')\n",
    "# plt.figure(figsize=(20,10), dpi = 500)\n",
    "# sns.heatmap(income_expenditure_corr,annot=True,fmt=\".2f\", linewidth=.5, cmap='coolwarm')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heatmap says that when income increases, expenditures slightly decreases. But overall, the two variables are highly correlated to each other, meaning that households are more likely to spend much of what they earn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now correlate income and expencitures with the various sources found in the dataset.\n",
    "Income will be correlated to monetary sources while expenditures will be correlated to various expenses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monetary_columns = [\n",
    "#     'Salaries/Wages from Regular Employment',\n",
    "#     'Salaries/Wages from Seasonal Employment',\n",
    "#     'Net Share of Crops, Fruits, etc. (Tot. Net Value of Share)',\n",
    "#     'Cash Receipts, Support, etc. from Abroad',\n",
    "#     'Cash Receipts, Support, etc. from Domestic Source',\n",
    "#     'Rentals Received from Non-Agri Lands, etc.',\n",
    "#     'Pension and Retirement Benefits',\n",
    "#     'Dividends from Investment',\n",
    "#     'Other Sources of Income NEC',\n",
    "#     'Family Sustenance Activities',\n",
    "#     'Total Received as Gifts',\n",
    "#     'Crop Farming and Gardening',\n",
    "#     'Livestock and Poultry Raising',\n",
    "#     'Fishing',\n",
    "#     'Forestry and Hunting',\n",
    "#     'Wholesale and Retail',\n",
    "#     'Manufacturing',\n",
    "#     'Transportation, Storage Services',\n",
    "#     'Entrep. Activities NEC',\n",
    "#     'Entrep. Activities NEC.1',\n",
    "#     'Entrep. Activities NEC.2',\n",
    "# ]\n",
    "\n",
    "# cost_columns = [\n",
    "#     'Cereal and Cereal Preparations (Total)',\n",
    "#     'Meat and Meat Preparations',\n",
    "#     'Fish and Marine Products (Total)',\n",
    "#     'Dairy Products and Eggs (Total)',\n",
    "#     'Oils and Fats (Total)',\n",
    "#     'Fruits and Vegetables',\n",
    "#     'Vegetables (Total)',\n",
    "#     'Sugar, Jam and Honey (Total)',\n",
    "#     'Food Not Elsewhere Classified (Total)',\n",
    "#     'Fruit and vegetable juices',\n",
    "#     'Coffee, Cocoa and Tea (Total)',\n",
    "#     'Tea (total)  expenditure',\n",
    "#     'Cocoa (total)  expenditure',\n",
    "#     'Main Source of Water Supply (2nd visit only)',\n",
    "#     'Softdrinks',\n",
    "#     'Other Non Alcoholic Beverages',\n",
    "#     'Alcoholic Beverages (Total)',\n",
    "#     'Tobacco (Total)',\n",
    "#     'Other Vegetables (Total)',\n",
    "#     'Services_Primary_Goods',\n",
    "#     'Alcohol Procduction Services',\n",
    "#     'Food Regularly Consumed Outside The Home (Total)',\n",
    "#     'Clothing, Footwear and Other Wear',\n",
    "#     'Housing and water (Total)',\n",
    "#     'Actual House Rent',\n",
    "#     'Furnishings, Household Equipment & Routine Household Mainte',\n",
    "#     'Health (Total)',\n",
    "#     'Transportation (Total)',\n",
    "#     'Communication (Total)',\n",
    "#     'Recreation and Culture (Total)',\n",
    "#     'Education (Total)',\n",
    "#     'Insurance',\n",
    "#     'Miscellaneous Goods and Services (Total)',\n",
    "#     'Durable Furniture',\n",
    "#     'Special Family Occasion',\n",
    "#     'Other Expenditure (inc. Value Consumed, Losses)',\n",
    "#     'Accomodation Services',\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have a smoother heatmap, all similar columns will be combined to a category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# income_dataframe = imputted_column_13[monetary_columns]\n",
    "\n",
    "# # Combine similar columns to reduce dimensionality\n",
    "# income_dataframe['Salaries/Wages'] = income_dataframe['Salaries/Wages from Regular Employment'] + income_dataframe['Salaries/Wages from Seasonal Employment']\n",
    "# income_dataframe['Cash Receipts'] = income_dataframe['Cash Receipts, Support, etc. from Abroad'] + income_dataframe['Cash Receipts, Support, etc. from Domestic Source']\n",
    "# income_dataframe['Farming'] = income_dataframe['Crop Farming and Gardening'] + income_dataframe['Net Share of Crops, Fruits, etc. (Tot. Net Value of Share)']\n",
    "# income_dataframe['Logistics and Manufacturing'] = income_dataframe['Wholesale and Retail'] + income_dataframe['Transportation, Storage Services'] + income_dataframe['Manufacturing']\n",
    "# income_dataframe['Entrep. Activities'] = income_dataframe['Entrep. Activities NEC'] + income_dataframe['Entrep. Activities NEC.1'] + income_dataframe['Entrep. Activities NEC.2']\n",
    "# income_dataframe['Passive Income'] = income_dataframe['Total Received as Gifts'] + income_dataframe['Family Sustenance Activities'] + income_dataframe['Pension and Retirement Benefits'] + income_dataframe['Dividends from Investment'] + income_dataframe['Rentals Received from Non-Agri Lands, etc.']\n",
    "# income_dataframe['Livestocks'] = income_dataframe['Livestock and Poultry Raising'] + income_dataframe['Fishing'] + income_dataframe['Forestry and Hunting']\n",
    "# income_dataframe['Other Income NEC'] = income_dataframe['Other Sources of Income NEC']\n",
    "\n",
    "# # Drop the original columns\n",
    "# income_dataframe.drop(columns=monetary_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# income_corr = income_dataframe.corr(method='pearson')\n",
    "# plt.figure(figsize=(20,10), dpi = 500)\n",
    "# sns.heatmap(income_corr,annot=True,fmt=\".2f\", linewidth=.5, cmap='coolwarm')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the heatmap above, all monetary sources are surprisingly not much correlated to each other. Negative correlations can be interpreted as households not having much revenue streams in many categories. Particularly in the Salaries/Wages column not having a positive correlation with other sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expenditure_dataframe = imputted_column_13[cost_columns]\n",
    "\n",
    "# expenditure_dataframe['Processed Foods'] = expenditure_dataframe['Cereal and Cereal Preparations (Total)'] + expenditure_dataframe['Sugar, Jam and Honey (Total)'] + expenditure_dataframe['Softdrinks'] + expenditure_dataframe['Oils and Fats (Total)']\n",
    "# expenditure_dataframe['Non-Processed Foods'] = expenditure_dataframe['Meat and Meat Preparations'] + expenditure_dataframe['Fish and Marine Products (Total)'] + expenditure_dataframe['Dairy Products and Eggs (Total)']\n",
    "# expenditure_dataframe['Other Foods'] = expenditure_dataframe['Food Not Elsewhere Classified (Total)'] + expenditure_dataframe['Food Regularly Consumed Outside The Home (Total)']\n",
    "# expenditure_dataframe['Fruits and Vegetables and Juices'] = expenditure_dataframe['Fruits and Vegetables'] + expenditure_dataframe['Vegetables (Total)'] + expenditure_dataframe['Fruit and vegetable juices'] + expenditure_dataframe['Other Vegetables (Total)']\n",
    "# expenditure_dataframe['Non-Alcoholic Beverages'] = expenditure_dataframe['Coffee, Cocoa and Tea (Total)'] + expenditure_dataframe['Tea (total)  expenditure'] + expenditure_dataframe['Cocoa (total)  expenditure'] + expenditure_dataframe['Other Non Alcoholic Beverages']\n",
    "# expenditure_dataframe['Non-Essential Expenditures'] = expenditure_dataframe['Alcoholic Beverages (Total)'] + expenditure_dataframe['Tobacco (Total)'] \n",
    "# expenditure_dataframe['Services and Primary Goods'] = expenditure_dataframe['Services_Primary_Goods'] + expenditure_dataframe['Main Source of Water Supply (2nd visit only)'] + expenditure_dataframe['Accomodation Services'] + expenditure_dataframe['Alcohol Procduction Services']\n",
    "# expenditure_dataframe['Miscellaneous Expenditures'] = expenditure_dataframe['Miscellaneous Goods and Services (Total)'] + expenditure_dataframe['Durable Furniture'] + expenditure_dataframe['Special Family Occasion']\n",
    "# expenditure_dataframe['Essential Expenditures'] = expenditure_dataframe['Clothing, Footwear and Other Wear'] + expenditure_dataframe['Housing and water (Total)'] + expenditure_dataframe['Actual House Rent'] + expenditure_dataframe['Furnishings, Household Equipment & Routine Household Mainte'] + expenditure_dataframe['Health (Total)']+ expenditure_dataframe['Transportation (Total)'] + expenditure_dataframe['Communication (Total)'] + expenditure_dataframe['Recreation and Culture (Total)'] + expenditure_dataframe['Education (Total)'] + expenditure_dataframe['Insurance']\n",
    "# expenditure_dataframe['Other Expenditure NEC'] = expenditure_dataframe['Other Expenditure (inc. Value Consumed, Losses)']\n",
    "\n",
    "# expenditure_dataframe.drop(columns=cost_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expenditure_corr = expenditure_dataframe.corr(method='pearson')\n",
    "# plt.figure(figsize=(20,10), dpi = 500)\n",
    "# sns.heatmap(expenditure_corr,annot=True,fmt=\".2f\", linewidth=.5, cmap='coolwarm')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the expenditure heatmap, it is very different from the income heatmap wherein all of the expenditure sources have positive correlations with one another. This indicates that households spend on various things while not having much revenue streams. Both of the Food categories and the Essential Expenditures have the highest correlation with the rest of the columns.\n",
    "\n",
    "The three heatmaps give a picture on the relationship of income-expenditure ratio for households, the relationship of revenue stream categories, and the relationship of spending habit of various households in the FIES dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate a distance matrix (e.g., Euclidean distance) for numeric data as required. Provide illustration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the computation of the distance matrix, Euclidean distance will be used to cluster households based on their income-expenditure ratio. Household Numbers provided in the dataset will be the main index of the distance matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance_dataframe = imputted_column_13.copy()\n",
    "# household_incomes = distance_dataframe['Hhld, Income, Total'].values\n",
    "# household_expenditures = distance_dataframe['Hhld, Expenditures, Total'].values\n",
    "# household_ids = distance_dataframe['Household ID'].values\n",
    "# household_df = pd.DataFrame({'Total Income': household_incomes, 'Total Expenditures': household_expenditures}, index=household_ids)\n",
    "# household_df.index = household_df.index.map(lambda x: f\"Household No. {x}\")\n",
    "# household_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset has about 149,622 entries even without the outliers, it is essential to reduce these entries so as to preserve computational power. The challenege now lies in finding a way to reduce rows but still keeping a good representation of the data. One such way researched is the <b>Freedman-Diaconis Rule</b> of getting the optimal number of bins to group the dataset into.\n",
    "\n",
    "The <b>Freedman-Diaconis Rule</b> is a method of determining the number of bins in a histogram. It is based on the interquartile range of the data. It was devised from the Scott's Rule, obtained by asymptotically minimizing the integral mean square error of the density estimate with respect to a Gaussian reference (Markov, 2022).\n",
    "\n",
    "The <b>Freedman-Diaconis Rule</b> will be implemented by finding the optimal number of bins to group the dataset into by income and expenditure. A Strata will be created by the combining the bins of income and expenditure into a string, by which a Stratified Sampling will be implemented to gain equal representation of the data. Stratas that areless than two will be dropped.\n",
    "\n",
    "Sources\n",
    "\n",
    "1. <https://medium.com/@maxmarkovvision/optimal-number-of-bins-for-histograms-3d7c48086fde>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_rows = household_df.shape[0]\n",
    "\n",
    "# income_iqr = household_df['Total Income'].quantile(0.75) - household_df['Total Income'].quantile(0.25)\n",
    "# expenditure_iqr = household_df['Total Expenditures'].quantile(0.75) - household_df['Total Expenditures'].quantile(0.25)\n",
    "\n",
    "# # Implement Freedman-Diaconis Rule\n",
    "# bin_width_income = 2 * income_iqr / (num_rows ** (1/3))\n",
    "# bin_width_expenditure = 2 * expenditure_iqr / (num_rows ** (1/3))\n",
    "\n",
    "# income_bins = int((household_df['Total Income'].max() - household_df['Total Income'].min()) / bin_width_income)\n",
    "# expenditure_bins = int((household_df['Total Expenditures'].max() - household_df['Total Expenditures'].min()) / bin_width_expenditure)\n",
    "\n",
    "# print(f\"Income number of bins: {income_bins}\")\n",
    "# print(f\"Expenditure number of bins: {expenditure_bins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# household_df['Income Bin'] = pd.qcut(household_df['Total Income'], q=income_bins, labels=False, duplicates='drop')\n",
    "# household_df['Expenditure Bin'] = pd.qcut(household_df['Total Expenditures'], q=expenditure_bins, labels=False, duplicates='drop')\n",
    "\n",
    "# household_df['Strata'] = household_df['Income Bin'].astype(str) + '-' + household_df['Expenditure Bin'].astype(str)\n",
    "# print(household_df['Strata'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Shape of the data before removing rare strata:\", household_df.shape)\n",
    "# strata_counts = household_df['Strata'].value_counts()\n",
    "# rare_strata = strata_counts[strata_counts < 2].index\n",
    "# # Drop the rare strata\n",
    "# household_df = household_df[~household_df['Strata'].isin(rare_strata)]\n",
    "\n",
    "# print(\"Shape of the data after removing rare strata:\", household_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now implement <b>Stratified Sampling</b> to get 5% of the data which will account for 7,434 rows for a balance of good representation of the data and a save in computational power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# sampled_df, _ = train_test_split(household_df, test_size=0.95, random_state=42, stratify=household_df['Strata']) # Get 5% of the data\n",
    "\n",
    "# sampled_df.drop(columns=['Income Bin', 'Expenditure Bin', 'Strata'], inplace=True)\n",
    "# print('Shape of sampled data:', sampled_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Euclidean Distance is sensitive to the scale of the data, we will normalize the data using Standard Scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# # Scale the data for Euclidean distance\n",
    "# scaled_data = StandardScaler().fit_transform(sampled_df)\n",
    "# scaled_data_df = pd.DataFrame(scaled_data, columns=sampled_df.columns, index=sampled_df.index)\n",
    "# scaled_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy will be used to calculate the Euclidean Distance and obtain the distance matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.spatial import distance_matrix\n",
    "\n",
    "# euclidean_distances = pd.DataFrame(distance_matrix(scaled_data, scaled_data), index=sampled_df.index, columns=sampled_df.index)\n",
    "# euclidean_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sample visualization, 10 samples will be used to create a heatmap. In this case, cooler colors means that households are closer to each other while warmer colors means that households are further away from each other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_samples = 10\n",
    "# sampled_indices = euclidean_distances.sample(n=n_samples, random_state=42).index\n",
    "# euclidean_distances_sampled = euclidean_distances.loc[sampled_indices, sampled_indices]\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.heatmap(euclidean_distances_sampled, cmap=\"coolwarm\", annot=False)\n",
    "# plt.title(\"Euclidean Distance Heatmap\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agglomerative Clustering directly works with a distance matrix as an input. We use the distance matrix of euclidean distances and form clusters based on similar household incomes and expenditures, and we add them to the sampled dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import AgglomerativeClustering\n",
    "# from sklearn.metrics import silhouette_score\n",
    "\n",
    "# silhouette_scores = []\n",
    "\n",
    "# for n_clusters in range(2, 11):\n",
    "#     clustering = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "#     labels = clustering.fit_predict(scaled_data)\n",
    "#     score = silhouette_score(scaled_data, labels)\n",
    "#     silhouette_scores.append(score)\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(range(2, 11), silhouette_scores, marker='o')\n",
    "# plt.xlabel('Number of Clusters')\n",
    "# plt.ylabel('Silhouette Score')\n",
    "# plt.title('Finding the Optimal Number of Clusters')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the silhouette score plot, the optimal number of clusters is 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_clusters = 2  \n",
    "\n",
    "# clustering = AgglomerativeClustering(n_clusters=num_clusters)\n",
    "# cluster_labels = clustering.fit_predict(euclidean_distances)\n",
    "\n",
    "# sampled_df['Cluster'] = cluster_labels\n",
    "# sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.scatterplot(\n",
    "#     x='Total Income', \n",
    "#     y='Total Expenditures', \n",
    "#     hue='Cluster', \n",
    "#     palette='viridis', \n",
    "#     data=sampled_df, \n",
    "#     s=100\n",
    "# )\n",
    "# plt.title('Cluster Visualization')\n",
    "# plt.xlabel('Total Income')\n",
    "# plt.ylabel('Total Expenditures')\n",
    "# plt.legend(title='Cluster')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scatterplot shows the clusters formed by the agglomerative clustering. We can see that the clusters are formed by similar households. In this case, two clusters are formed.\n",
    "\n",
    "1. The 0 Cluster are households with relatively high to upper middle income and high expenditures\n",
    "2. The 1 Cluster are households with relatively low to lower middle income and expenditures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# income_dataframe.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# similarity_matrix = cosine_similarity(sampled_df[sampled_df.columns])\n",
    "# print(similarity_matrix[:5, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Data Mining: Association Rule Mining\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If needed, transform the dataset (one-hot encoding) and apply the Apriori algorithm to extract association rules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance_dataframe = imputted_column_13.copy()\n",
    "# household_incomes = distance_dataframe['Hhld, Income, Total'].values\n",
    "# household_expenditures = distance_dataframe['Hhld, Expenditures, Total'].values\n",
    "# household_ids = distance_dataframe['Household ID'].values\n",
    "# household_df = pd.DataFrame({'Total Income': household_incomes, 'Total Expenditures': household_expenditures}, index=household_ids)\n",
    "# household_df.index = household_df.index.map(lambda x: f\"Household No. {x}\")\n",
    "# household_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assoc_rule_sampling = imputted_column_13.copy()\n",
    "\n",
    "num_rows = assoc_rule_sampling.shape[0]\n",
    "\n",
    "income_iqr = assoc_rule_sampling['Hhld, Income, Total'].quantile(0.75) - assoc_rule_sampling['Hhld, Income, Total'].quantile(0.25)\n",
    "expenditure_iqr = assoc_rule_sampling['Hhld, Expenditures, Total'].quantile(0.75) - assoc_rule_sampling['Hhld, Expenditures, Total'].quantile(0.25)\n",
    "\n",
    "# Implement Freedman-Diaconis Rule\n",
    "bin_width_income = 2 * income_iqr / (num_rows ** (1/3))\n",
    "bin_width_expenditure = 2 * expenditure_iqr / (num_rows ** (1/3))\n",
    "\n",
    "income_bins = int((assoc_rule_sampling['Hhld, Income, Total'].max() - assoc_rule_sampling['Hhld, Income, Total'].min()) / bin_width_income)\n",
    "expenditure_bins = int((assoc_rule_sampling['Hhld, Expenditures, Total'].max() - assoc_rule_sampling['Hhld, Expenditures, Total'].min()) / bin_width_expenditure)\n",
    "\n",
    "print(f\"Income number of bins: {income_bins}\")\n",
    "print(f\"Expenditure number of bins: {expenditure_bins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assoc_rule_sampling['Income Bin'] = pd.qcut(assoc_rule_sampling['Hhld, Income, Total'], q=income_bins, labels=False, duplicates='drop')\n",
    "assoc_rule_sampling['Expenditure Bin'] = pd.qcut(assoc_rule_sampling['Hhld, Expenditures, Total'], q=expenditure_bins, labels=False, duplicates='drop')\n",
    "\n",
    "assoc_rule_sampling['Strata'] = assoc_rule_sampling['Income Bin'].astype(str) + '-' + assoc_rule_sampling['Expenditure Bin'].astype(str)\n",
    "print(assoc_rule_sampling['Strata'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of the data before removing rare strata:\", assoc_rule_sampling.shape)\n",
    "strata_counts = assoc_rule_sampling['Strata'].value_counts()\n",
    "rare_strata = strata_counts[strata_counts < 2].index\n",
    "# Drop the rare strata\n",
    "assoc_rule_sampling = assoc_rule_sampling[~assoc_rule_sampling['Strata'].isin(rare_strata)]\n",
    "\n",
    "print(\"Shape of the data after removing rare strata:\", assoc_rule_sampling.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "assoc_rule_sampled, _ = train_test_split(assoc_rule_sampling, test_size=0.95, random_state=42, stratify=assoc_rule_sampling['Strata']) # Get 5% of the data\n",
    "\n",
    "assoc_rule_sampled.drop(columns=['Income Bin', 'Expenditure Bin', 'Strata'], inplace=True)\n",
    "print('Shape of sampled data:', assoc_rule_sampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monetary_columns = [\n",
    "    'Salaries/Wages from Regular Employment',\n",
    "    'Salaries/Wages from Seasonal Employment',\n",
    "    'Net Share of Crops, Fruits, etc. (Tot. Net Value of Share)',\n",
    "    'Cash Receipts, Support, etc. from Abroad',\n",
    "    'Cash Receipts, Support, etc. from Domestic Source',\n",
    "    'Rentals Received from Non-Agri Lands, etc.',\n",
    "    'Pension and Retirement Benefits',\n",
    "    'Dividends from Investment',\n",
    "    'Other Sources of Income NEC',\n",
    "    'Family Sustenance Activities',\n",
    "    'Total Received as Gifts',\n",
    "    'Crop Farming and Gardening',\n",
    "    'Livestock and Poultry Raising',\n",
    "    'Fishing',\n",
    "    'Forestry and Hunting',\n",
    "    'Wholesale and Retail',\n",
    "    'Manufacturing',\n",
    "    'Transportation, Storage Services',\n",
    "    'Entrep. Activities NEC',\n",
    "    'Entrep. Activities NEC.1',\n",
    "    'Entrep. Activities NEC.2',\n",
    "]\n",
    "cost_columns = [\n",
    "    'Cereal and Cereal Preparations (Total)',\n",
    "    'Meat and Meat Preparations',\n",
    "    'Fish and Marine Products (Total)',\n",
    "    'Dairy Products and Eggs (Total)',\n",
    "    'Oils and Fats (Total)',\n",
    "    'Fruits and Vegetables',\n",
    "    'Vegetables (Total)',\n",
    "    'Sugar, Jam and Honey (Total)',\n",
    "    'Food Not Elsewhere Classified (Total)',\n",
    "    'Fruit and vegetable juices',\n",
    "    'Coffee, Cocoa and Tea (Total)',\n",
    "    'Tea (total)  expenditure',\n",
    "    'Cocoa (total)  expenditure',\n",
    "    'Main Source of Water Supply (2nd visit only)',\n",
    "    'Softdrinks',\n",
    "    'Other Non Alcoholic Beverages',\n",
    "    'Alcoholic Beverages (Total)',\n",
    "    'Tobacco (Total)',\n",
    "    'Other Vegetables (Total)',\n",
    "    'Services_Primary_Goods',\n",
    "    'Alcohol Procduction Services',\n",
    "    'Food Regularly Consumed Outside The Home (Total)',\n",
    "    'Clothing, Footwear and Other Wear',\n",
    "    'Housing and water (Total)',\n",
    "    'Actual House Rent',\n",
    "    'Furnishings, Household Equipment & Routine Household Mainte',\n",
    "    'Health (Total)',\n",
    "    'Transportation (Total)',\n",
    "    'Communication (Total)',\n",
    "    'Recreation and Culture (Total)',\n",
    "    'Education (Total)',\n",
    "    'Insurance',\n",
    "    'Miscellaneous Goods and Services (Total)',\n",
    "    'Durable Furniture',\n",
    "    'Special Family Occasion',\n",
    "    'Other Expenditure (inc. Value Consumed, Losses)',\n",
    "    'Accomodation Services',\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assoc_rule_1 = assoc_rule_sampled.copy()\n",
    "# categorical_columns = [\"NPCINC\"]\n",
    "assoc_rule_1 = assoc_rule_1[monetary_columns + cost_columns].copy()\n",
    "# Combine similar columns to reduce dimensionality\n",
    "assoc_rule_1['Salaries/Wages'] = assoc_rule_1['Salaries/Wages from Regular Employment'] + assoc_rule_1['Salaries/Wages from Seasonal Employment']\n",
    "assoc_rule_1['Cash Receipts'] = assoc_rule_1['Cash Receipts, Support, etc. from Abroad'] + assoc_rule_1['Cash Receipts, Support, etc. from Domestic Source']\n",
    "assoc_rule_1['Farming'] = assoc_rule_1['Crop Farming and Gardening'] + assoc_rule_1['Net Share of Crops, Fruits, etc. (Tot. Net Value of Share)']\n",
    "assoc_rule_1['Logistics and Manufacturing'] = assoc_rule_1['Wholesale and Retail'] + assoc_rule_1['Transportation, Storage Services'] + assoc_rule_1['Manufacturing']\n",
    "assoc_rule_1['Entrep. Activities'] = assoc_rule_1['Entrep. Activities NEC'] + assoc_rule_1['Entrep. Activities NEC.1'] + assoc_rule_1['Entrep. Activities NEC.2']\n",
    "assoc_rule_1['Passive Income'] = assoc_rule_1['Total Received as Gifts'] + assoc_rule_1['Family Sustenance Activities'] + assoc_rule_1['Pension and Retirement Benefits'] + assoc_rule_1['Dividends from Investment'] + assoc_rule_1['Rentals Received from Non-Agri Lands, etc.']\n",
    "assoc_rule_1['Livestocks'] = assoc_rule_1['Livestock and Poultry Raising'] + assoc_rule_1['Fishing'] + assoc_rule_1['Forestry and Hunting']\n",
    "assoc_rule_1['Other Income NEC'] = assoc_rule_1['Other Sources of Income NEC']\n",
    "\n",
    "# Drop the original columns\n",
    "assoc_rule_1['Processed Foods'] = assoc_rule_1['Cereal and Cereal Preparations (Total)'] + assoc_rule_1['Sugar, Jam and Honey (Total)'] + assoc_rule_1['Softdrinks'] + assoc_rule_1['Oils and Fats (Total)']\n",
    "assoc_rule_1['Non-Processed Foods'] = assoc_rule_1['Meat and Meat Preparations'] + assoc_rule_1['Fish and Marine Products (Total)'] + assoc_rule_1['Dairy Products and Eggs (Total)']\n",
    "assoc_rule_1['Other Foods'] = assoc_rule_1['Food Not Elsewhere Classified (Total)'] + assoc_rule_1['Food Regularly Consumed Outside The Home (Total)']\n",
    "assoc_rule_1['Fruits and Vegetables and Juices'] = assoc_rule_1['Fruits and Vegetables'] + assoc_rule_1['Vegetables (Total)'] + assoc_rule_1['Fruit and vegetable juices'] + assoc_rule_1['Other Vegetables (Total)']\n",
    "assoc_rule_1['Non-Alcoholic Beverages'] = assoc_rule_1['Coffee, Cocoa and Tea (Total)'] + assoc_rule_1['Tea (total)  expenditure'] + assoc_rule_1['Cocoa (total)  expenditure'] + assoc_rule_1['Other Non Alcoholic Beverages']\n",
    "assoc_rule_1['Non-Essential Expenditures'] = assoc_rule_1['Alcoholic Beverages (Total)'] + assoc_rule_1['Tobacco (Total)'] \n",
    "assoc_rule_1['Services and Primary Goods'] = assoc_rule_1['Services_Primary_Goods'] + assoc_rule_1['Main Source of Water Supply (2nd visit only)'] + assoc_rule_1['Accomodation Services'] + assoc_rule_1['Alcohol Procduction Services']\n",
    "assoc_rule_1['Miscellaneous Expenditures'] = assoc_rule_1['Miscellaneous Goods and Services (Total)'] + assoc_rule_1['Durable Furniture'] + assoc_rule_1['Special Family Occasion']\n",
    "assoc_rule_1['Essential Expenditures'] = assoc_rule_1['Clothing, Footwear and Other Wear'] + assoc_rule_1['Housing and water (Total)'] + assoc_rule_1['Actual House Rent'] + assoc_rule_1['Furnishings, Household Equipment & Routine Household Mainte'] + assoc_rule_1['Health (Total)']+ assoc_rule_1['Transportation (Total)'] + assoc_rule_1['Communication (Total)'] + assoc_rule_1['Recreation and Culture (Total)'] + assoc_rule_1['Education (Total)'] + assoc_rule_1['Insurance']\n",
    "assoc_rule_1['Other Expenditure NEC'] = assoc_rule_1['Other Expenditure (inc. Value Consumed, Losses)']\n",
    "\n",
    "assoc_rule_1.drop(columns=monetary_columns, inplace=True)\n",
    "assoc_rule_1.drop(columns=cost_columns, inplace=True)\n",
    "\n",
    "# convert monetary and cost to low/med/high using percentiles\n",
    "def categorize_lmh(value, quantiles):\n",
    "    if value == 0:\n",
    "        return \"None\"\n",
    "    if value <= quantiles[0.33]:\n",
    "        return \"Low\"\n",
    "    elif value <= quantiles[0.66]:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "    \n",
    "for col in assoc_rule_1.columns:\n",
    "    quantiles = assoc_rule_1[col].quantile([0.33, 0.66]).to_dict()\n",
    "    assoc_rule_1[col] = assoc_rule_1[col].apply(lambda x: categorize_lmh(x, quantiles))\n",
    "\n",
    "assoc_rule_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assoc_rule_1_transactions = pd.get_dummies(assoc_rule_1)\n",
    "assoc_rule_1_transactions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "frequent_itemsets = fpgrowth(assoc_rule_1_transactions, min_support=0.3, use_colnames=True, verbose=1)\n",
    "# 0.3 support in a 7434 dataset is 7434 * 0.3 = 2294 transactions where the item / combination is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "# save frequent itemsets and association rules to csv\n",
    "frequent_itemsets.to_csv('../itemsets_and_rules/frequent_itemsets_spendingPatterns.csv', index=False)\n",
    "rules.to_csv('../itemsets_and_rules/association_rules_spendingPatterns.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "# Convert frozensets to strings for JSON serialization\n",
    "rules['antecedents'] = rules['antecedents'].apply(lambda x: ', '.join(list(x)))\n",
    "rules['consequents'] = rules['consequents'].apply(lambda x: ', '.join(list(x)))\n",
    "\n",
    "unique_values = sorted(set(rules[\"antecedents\"]).union(set(rules[\"consequents\"])))\n",
    "unique_values.insert(0, \"All\")  # Add \"All\" at the beginning\n",
    "\n",
    "value_dropdown = widgets.Dropdown(\n",
    "    options=unique_values, \n",
    "    value=\"All\",  # Default selection\n",
    "    description='Filter:'\n",
    ")\n",
    "\n",
    "def update_plot(selected_value):\n",
    "    if selected_value == \"All\":\n",
    "        filtered_rules = rules  # Show full dataset\n",
    "    else:\n",
    "        # Filter the DataFrame where antecedents or consequents contain the selected value\n",
    "        filtered_rules = rules[\n",
    "            (rules[\"antecedents\"] == selected_value) | (rules[\"consequents\"] == selected_value)\n",
    "        ]\n",
    "    \n",
    "    if filtered_rules.empty:\n",
    "        print(f\"No rules found for '{selected_value}'\")\n",
    "        return\n",
    "\n",
    "    # Create the scatter plot\n",
    "    fig = px.scatter(\n",
    "        filtered_rules,\n",
    "        x='support',\n",
    "        y='confidence',\n",
    "        size='lift',\n",
    "        color='lift',\n",
    "        hover_name='antecedents',\n",
    "        hover_data=['consequents', 'support', 'confidence', 'lift'],\n",
    "        title=f'Rules Involving \"{selected_value}\"' if selected_value != \"All\" else \"All Rules\",\n",
    "        labels={'support': 'Support', 'confidence': 'Confidence'},\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# Display interactive widgets\n",
    "interactive_plot = widgets.interactive(update_plot, selected_value=value_dropdown)\n",
    "display(interactive_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assoc_rule_2 = assoc_rule_sampled.copy()\n",
    "assoc_rule_2 = assoc_rule_2[monetary_columns].copy()\n",
    "# Combine similar columns to reduce dimensionality\n",
    "assoc_rule_2['Salaries/Wages'] = assoc_rule_2['Salaries/Wages from Regular Employment'] + assoc_rule_2['Salaries/Wages from Seasonal Employment']\n",
    "assoc_rule_2['Cash Receipts'] = assoc_rule_2['Cash Receipts, Support, etc. from Abroad'] + assoc_rule_2['Cash Receipts, Support, etc. from Domestic Source']\n",
    "assoc_rule_2['Farming'] = assoc_rule_2['Crop Farming and Gardening'] + assoc_rule_2['Net Share of Crops, Fruits, etc. (Tot. Net Value of Share)']\n",
    "assoc_rule_2['Logistics and Manufacturing'] = assoc_rule_2['Wholesale and Retail'] + assoc_rule_2['Transportation, Storage Services'] + assoc_rule_2['Manufacturing']\n",
    "assoc_rule_2['Entrep. Activities'] = assoc_rule_2['Entrep. Activities NEC'] + assoc_rule_2['Entrep. Activities NEC.1'] + assoc_rule_2['Entrep. Activities NEC.2']\n",
    "assoc_rule_2['Passive Income'] = assoc_rule_2['Total Received as Gifts'] + assoc_rule_2['Family Sustenance Activities'] + assoc_rule_2['Pension and Retirement Benefits'] + assoc_rule_2['Dividends from Investment'] + assoc_rule_2['Rentals Received from Non-Agri Lands, etc.']\n",
    "assoc_rule_2['Livestocks'] = assoc_rule_2['Livestock and Poultry Raising'] + assoc_rule_2['Fishing'] + assoc_rule_2['Forestry and Hunting']\n",
    "assoc_rule_2['Other Income NEC'] = assoc_rule_2['Other Sources of Income NEC']\n",
    "\n",
    "assoc_rule_2.drop(columns=monetary_columns, inplace=True)\n",
    "\n",
    "def categorize_lmh(value, quantiles):\n",
    "    if value == 0:\n",
    "        return \"None\"\n",
    "    if value <= quantiles[0.33]:\n",
    "        return \"Low\"\n",
    "    elif value <= quantiles[0.66]:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "    \n",
    "for col in assoc_rule_2.columns:\n",
    "    quantiles = assoc_rule_2[col].quantile([0.33, 0.66]).to_dict()\n",
    "    assoc_rule_2[col] = assoc_rule_2[col].apply(lambda x: categorize_lmh(x, quantiles))\n",
    "\n",
    "assoc_rule_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assoc_rule_2_transactions = pd.get_dummies(assoc_rule_2)\n",
    "assoc_rule_2_transactions.shape\n",
    "frequent_itemsets_2 = fpgrowth(assoc_rule_2_transactions, min_support=0.1, use_colnames=True, verbose=1)\n",
    "rules_2 = association_rules(frequent_itemsets_2, metric=\"lift\", min_threshold=1)\n",
    "# save frequent itemsets and association rules_2 to csv\n",
    "frequent_itemsets_2.to_csv('../itemsets_and_rules/frequent_itemsets_financialFreedom.csv', index=False)\n",
    "rules_2.to_csv('../itemsets_and_rules/association_rules_financialFreedom.csv', index=False)\n",
    "rules_2['antecedents'] = rules_2['antecedents'].apply(lambda x: ', '.join(list(x)))\n",
    "rules_2['consequents'] = rules_2['consequents'].apply(lambda x: ', '.join(list(x)))\n",
    "\n",
    "unique_values = sorted(set(rules_2[\"antecedents\"]).union(set(rules_2[\"consequents\"])))\n",
    "unique_values.insert(0, \"All\")  # Add \"All\" at the beginning\n",
    "\n",
    "value_dropdown = widgets.Dropdown(\n",
    "    options=unique_values, \n",
    "    value=\"All\",  \n",
    "    description='Filter:'\n",
    ")\n",
    "\n",
    "def update_plot(selected_value):\n",
    "    if selected_value == \"All\":\n",
    "        filtered_rules = rules_2  \n",
    "    else:\n",
    "        filtered_rules = rules_2[\n",
    "            (rules_2[\"antecedents\"] == selected_value) | (rules_2[\"consequents\"] == selected_value)\n",
    "        ]\n",
    "    \n",
    "    if filtered_rules.empty:\n",
    "        print(f\"No rules_2 found for '{selected_value}'\")\n",
    "        return\n",
    "\n",
    "    # Create the scatter plot\n",
    "    fig = px.scatter(\n",
    "        filtered_rules,\n",
    "        x='support',\n",
    "        y='confidence',\n",
    "        size='lift',\n",
    "        color='lift',\n",
    "        hover_name='antecedents',\n",
    "        hover_data=['consequents', 'support', 'confidence', 'lift'],\n",
    "        title=f'Rules Involving \"{selected_value}\"' if selected_value != \"All\" else \"All Rules\",\n",
    "        labels={'support': 'Support', 'confidence': 'Confidence'},\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "interactive_plot = widgets.interactive(update_plot, selected_value=value_dropdown)\n",
    "display(interactive_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assoc_rule_3 = imputted_column_13.copy()\n",
    "categorical_columns = ['Region']\n",
    "assoc_rule_3 = assoc_rule_3[monetary_columns + categorical_columns].copy()\n",
    "\n",
    "assoc_rule_3['Salaries/Wages'] = assoc_rule_3['Salaries/Wages from Regular Employment'] + assoc_rule_3['Salaries/Wages from Seasonal Employment']\n",
    "assoc_rule_3['Cash Receipts'] = assoc_rule_3['Cash Receipts, Support, etc. from Abroad'] + assoc_rule_3['Cash Receipts, Support, etc. from Domestic Source']\n",
    "assoc_rule_3['Farming'] = assoc_rule_3['Crop Farming and Gardening'] + assoc_rule_3['Net Share of Crops, Fruits, etc. (Tot. Net Value of Share)']\n",
    "assoc_rule_3['Logistics and Manufacturing'] = assoc_rule_3['Wholesale and Retail'] + assoc_rule_3['Transportation, Storage Services'] + assoc_rule_3['Manufacturing']\n",
    "assoc_rule_3['Entrep. Activities'] = assoc_rule_3['Entrep. Activities NEC'] + assoc_rule_3['Entrep. Activities NEC.1'] + assoc_rule_3['Entrep. Activities NEC.2']\n",
    "assoc_rule_3['Passive Income'] = assoc_rule_3['Total Received as Gifts'] + assoc_rule_3['Family Sustenance Activities'] + assoc_rule_3['Pension and Retirement Benefits'] + assoc_rule_3['Dividends from Investment'] + assoc_rule_3['Rentals Received from Non-Agri Lands, etc.']\n",
    "assoc_rule_3['Livestocks'] = assoc_rule_3['Livestock and Poultry Raising'] + assoc_rule_3['Fishing'] + assoc_rule_3['Forestry and Hunting']\n",
    "assoc_rule_3['Other Income NEC'] = assoc_rule_3['Other Sources of Income NEC']\n",
    "\n",
    "assoc_rule_3.drop(columns=monetary_columns, inplace=True)\n",
    "\n",
    "assoc_rule_3, _ = train_test_split(assoc_rule_3, test_size=0.95, random_state=42, stratify=assoc_rule_3['Region']) \n",
    "\n",
    "def categorize_lmh(value, quantiles):\n",
    "    if value == 0:\n",
    "        return \"None\"\n",
    "    if value <= quantiles[0.33]:\n",
    "        return \"Low\"\n",
    "    elif value <= quantiles[0.66]:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "\n",
    "def categorize_region(value):\n",
    "    luzon = {\n",
    "        1: 'Ilocos Region',\n",
    "        2: 'Cagayan Valley',\n",
    "        3: 'Central Luzon',\n",
    "        4: 'CALABARZON',\n",
    "        5: 'Bicol',\n",
    "        13: 'NCR',\n",
    "        14: 'CAR',\n",
    "        17: 'MIMAROPA'\n",
    "    }\n",
    "    visayas = {\n",
    "        6: 'Western Visayas',\n",
    "        7: 'Central Visayas',\n",
    "        8: 'Eastern Visayas'\n",
    "    }\n",
    "    mindanao = {\n",
    "        9: 'Zamboanga Peninsula',\n",
    "        10: 'Northern Mindanao',\n",
    "        11: 'Davao Region',\n",
    "        12: 'Soccsksargen',\n",
    "        16: 'Caraga',\n",
    "        19: 'BARMM'\n",
    "    }\n",
    "    if value in luzon:\n",
    "        return \"Luzon\"\n",
    "    elif value in visayas:\n",
    "        return \"Visayas\"\n",
    "    elif value in mindanao:\n",
    "        return \"Mindanao\"\n",
    "for col in assoc_rule_3.columns:\n",
    "    if col == 'Region':\n",
    "        assoc_rule_3[col] = assoc_rule_3[col].apply(categorize_region)\n",
    "    else:\n",
    "        quantiles = assoc_rule_3[col].quantile([0.33, 0.66]).to_dict()\n",
    "        assoc_rule_3[col] = assoc_rule_3[col].apply(lambda x: categorize_lmh(x, quantiles))\n",
    "\n",
    "assoc_rule_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assoc_rule_3_transactions = pd.get_dummies(assoc_rule_3)\n",
    "assoc_rule_3_transactions.shape\n",
    "frequent_itemsets_3 = fpgrowth(assoc_rule_3_transactions, min_support=0.1, use_colnames=True, verbose=1)\n",
    "rules_3 = association_rules(frequent_itemsets_3, metric=\"lift\", min_threshold=1)\n",
    "# save frequent itemsets and association rules_3 to csv\n",
    "frequent_itemsets_3.to_csv('../itemsets_and_rules/frequent_itemsets_financialFreedomPerRegion.csv', index=False)\n",
    "rules_3.to_csv('../itemsets_and_rules/association_rules_financialFreedomPerRegion.csv', index=False)\n",
    "rules_3['antecedents'] = rules_3['antecedents'].apply(lambda x: ', '.join(list(x)))\n",
    "rules_3['consequents'] = rules_3['consequents'].apply(lambda x: ', '.join(list(x)))\n",
    "\n",
    "unique_values = sorted(set(rules_3[\"antecedents\"]).union(set(rules_3[\"consequents\"])))\n",
    "unique_values.insert(0, \"All\")  # Add \"All\" at the beginning\n",
    "\n",
    "value_dropdown = widgets.Dropdown(\n",
    "    options=unique_values, \n",
    "    value=\"All\",  \n",
    "    description='Filter:'\n",
    ")\n",
    "\n",
    "def update_plot(selected_value):\n",
    "    if selected_value == \"All\":\n",
    "        filtered_rules = rules_3  \n",
    "    else:\n",
    "        filtered_rules = rules_3[\n",
    "            (rules_3[\"antecedents\"] == selected_value) | (rules_3[\"consequents\"] == selected_value)\n",
    "        ]\n",
    "    \n",
    "    if filtered_rules.empty:\n",
    "        print(f\"No rules_3 found for '{selected_value}'\")\n",
    "        return\n",
    "\n",
    "    # Create the scatter plot\n",
    "    fig = px.scatter(\n",
    "        filtered_rules,\n",
    "        x='support',\n",
    "        y='confidence',\n",
    "        size='lift',\n",
    "        color='lift',\n",
    "        hover_name='antecedents',\n",
    "        hover_data=['consequents', 'support', 'confidence', 'lift'],\n",
    "        title=f'Rules Involving \"{selected_value}\"' if selected_value != \"All\" else \"All Rules\",\n",
    "        labels={'support': 'Support', 'confidence': 'Confidence'},\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "interactive_plot = widgets.interactive(update_plot, selected_value=value_dropdown)\n",
    "display(interactive_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assoc_rule_4 = imputted_column_13.copy()\n",
    "categorical_columns = ['NPCINC']\n",
    "assoc_rule_4 = assoc_rule_4[monetary_columns + categorical_columns].copy()\n",
    "# Combine similar columns to reduce dimensionality\n",
    "assoc_rule_4['Salaries/Wages'] = assoc_rule_4['Salaries/Wages from Regular Employment'] + assoc_rule_4['Salaries/Wages from Seasonal Employment']\n",
    "assoc_rule_4['Cash Receipts'] = assoc_rule_4['Cash Receipts, Support, etc. from Abroad'] + assoc_rule_4['Cash Receipts, Support, etc. from Domestic Source']\n",
    "assoc_rule_4['Farming'] = assoc_rule_4['Crop Farming and Gardening'] + assoc_rule_4['Net Share of Crops, Fruits, etc. (Tot. Net Value of Share)']\n",
    "assoc_rule_4['Logistics and Manufacturing'] = assoc_rule_4['Wholesale and Retail'] + assoc_rule_4['Transportation, Storage Services'] + assoc_rule_4['Manufacturing']\n",
    "assoc_rule_4['Entrep. Activities'] = assoc_rule_4['Entrep. Activities NEC'] + assoc_rule_4['Entrep. Activities NEC.1'] + assoc_rule_4['Entrep. Activities NEC.2']\n",
    "assoc_rule_4['Passive Income'] = assoc_rule_4['Total Received as Gifts'] + assoc_rule_4['Family Sustenance Activities'] + assoc_rule_4['Pension and Retirement Benefits'] + assoc_rule_4['Dividends from Investment'] + assoc_rule_4['Rentals Received from Non-Agri Lands, etc.']\n",
    "assoc_rule_4['Livestocks'] = assoc_rule_4['Livestock and Poultry Raising'] + assoc_rule_4['Fishing'] + assoc_rule_4['Forestry and Hunting']\n",
    "assoc_rule_4['Other Income NEC'] = assoc_rule_4['Other Sources of Income NEC']\n",
    "\n",
    "assoc_rule_4.drop(columns=monetary_columns, inplace=True)\n",
    "assoc_rule_4, _ = train_test_split(assoc_rule_4, test_size=0.95, random_state=42, stratify=assoc_rule_4['NPCINC']) \n",
    "def categorize_lmh(value, quantiles):\n",
    "    if value == 0:\n",
    "        return \"None\"\n",
    "    if value <= quantiles[0.33]:\n",
    "        return \"Low\"\n",
    "    elif value <= quantiles[0.66]:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "\n",
    "def categorize_income(decile):\n",
    "    if 1 <= decile <= 3:\n",
    "        return 'Low Income'\n",
    "    elif 4 <= decile <= 7:\n",
    "        return 'Middle Income'\n",
    "    elif 8 <= decile <= 10:\n",
    "        return 'High Income'\n",
    "    else:\n",
    "        return 'Invalid Decile'\n",
    "    \n",
    "for col in assoc_rule_4.columns:\n",
    "    if col == 'NPCINC':\n",
    "        assoc_rule_4[col] = assoc_rule_4[col].apply(categorize_income)\n",
    "    else:\n",
    "        quantiles = assoc_rule_4[col].quantile([0.33, 0.66]).to_dict()\n",
    "        assoc_rule_4[col] = assoc_rule_4[col].apply(lambda x: categorize_lmh(x, quantiles))\n",
    "\n",
    "assoc_rule_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assoc_rule_4_transactions = pd.get_dummies(assoc_rule_4)\n",
    "assoc_rule_4_transactions.shape\n",
    "frequent_itemsets_4 = fpgrowth(assoc_rule_4_transactions, min_support=0.1, use_colnames=True, verbose=1)\n",
    "rules_4 = association_rules(frequent_itemsets_4, metric=\"lift\", min_threshold=1)\n",
    "# save frequent itemsets and association rules_4 to csv\n",
    "frequent_itemsets_4.to_csv('../itemsets_and_rules/frequent_itemsets_financialFreedomPerIncomeGroup.csv', index=False)\n",
    "rules_4.to_csv('../itemsets_and_rules/association_rules_financialFreedomPerIncomeGroup.csv', index=False)\n",
    "rules_4['antecedents'] = rules_4['antecedents'].apply(lambda x: ', '.join(list(x)))\n",
    "rules_4['consequents'] = rules_4['consequents'].apply(lambda x: ', '.join(list(x)))\n",
    "\n",
    "unique_values = sorted(set(rules_4[\"antecedents\"]).union(set(rules_4[\"consequents\"])))\n",
    "unique_values.insert(0, \"All\")  # Add \"All\" at the beginning\n",
    "\n",
    "value_dropdown = widgets.Dropdown(\n",
    "    options=unique_values, \n",
    "    value=\"All\",  \n",
    "    description='Filter:'\n",
    ")\n",
    "\n",
    "def update_plot(selected_value):\n",
    "    if selected_value == \"All\":\n",
    "        filtered_rules = rules_4  \n",
    "    else:\n",
    "        filtered_rules = rules_4[\n",
    "            (rules_4[\"antecedents\"] == selected_value) | (rules_4[\"consequents\"] == selected_value)\n",
    "        ]\n",
    "    \n",
    "    if filtered_rules.empty:\n",
    "        print(f\"No rules_4 found for '{selected_value}'\")\n",
    "        return\n",
    "\n",
    "    # Create the scatter plot\n",
    "    fig = px.scatter(\n",
    "        filtered_rules,\n",
    "        x='support',\n",
    "        y='confidence',\n",
    "        size='lift',\n",
    "        color='lift',\n",
    "        hover_name='antecedents',\n",
    "        hover_data=['consequents', 'support', 'confidence', 'lift'],\n",
    "        title=f'Rules Involving \"{selected_value}\"' if selected_value != \"All\" else \"All Rules\",\n",
    "        labels={'support': 'Support', 'confidence': 'Confidence'},\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "interactive_plot = widgets.interactive(update_plot, selected_value=value_dropdown)\n",
    "display(interactive_plot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataMining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
